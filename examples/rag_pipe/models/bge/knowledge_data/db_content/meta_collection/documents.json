[{"id": 0, "contents": "title: Dynamic Network Model from Partial Observations\nauthors: Elahe Ghalebi,Baharan Mirzasoleiman,Radu Grosu,Jure Leskovec\nabstract: Can evolving networks be inferred and modeled without directly observing\ntheir nodes and edges? In many applications, the edges of a dynamic network\nmight not be observed, but one can observe the dynamics of stochastic cascading\nprocesses (e.g., information diffusion, virus propagation) occurring over the\nunobserved network. While there have been efforts to infer networks based on\nsuch data, providing a generative probabilistic model that is able to identify\nthe underlying time-varying network remains an open question. Here we consider\nthe problem of inferring generative dynamic network models based on network\ncascade diffusion data. We propose a novel framework for providing a\nnon-parametric dynamic network model--based on a mixture of coupled\nhierarchical Dirichlet processes-- based on data capturing cascade node\ninfection times. Our approach allows us to infer the evolving community\nstructure in networks and to obtain an explicit predictive distribution over\nthe edges of the underlying network--including those that were not involved in\ntransmission of any cascade, or are likely to appear in the future. We show the\neffectiveness of our approach using extensive experiments on synthetic as well\nas real-world networks.\ndetails: "}, {"id": 1, "contents": "title: PAC-Bayes bounds for stable algorithms with instance-dependent priors\nauthors: Omar Rivasplata,Emilio Parrado-Hernandez,John Shawe-Taylor,Shiliang Sun,Csaba Szepesvari\nabstract: PAC-Bayes bounds have been proposed to get risk estimates based on a training\nsample. In this paper the PAC-Bayes approach is combined with stability of the\nhypothesis learned by a Hilbert space valued algorithm. The PAC-Bayes setting\nis used with a Gaussian prior centered at the expected output. Thus a novelty\nof our paper is using priors defined in terms of the data-generating\ndistribution. Our main result estimates the risk of the randomized algorithm in\nterms of the hypothesis stability coefficients. We also provide a new bound for\nthe SVM classifier, which is compared to other known bounds experimentally.\nOurs appears to be the first stability-based bound that evaluates to\nnon-trivial values.\ndetails: "}, {"id": 2, "contents": "title: Automated Bridge Component Recognition using Video Data\nauthors: Yasutaka Narazaki,Vedhus Hoskere,Tu A. Hoang,Billie F. Spencer Jr\nabstract: This paper investigates the automated recognition of structural bridge\ncomponents using video data. Although understanding video data for structural\ninspections is straightforward for human inspectors, the implementation of the\nsame task using machine learning methods has not been fully realized. In\nparticular, single-frame image processing techniques, such as convolutional\nneural networks (CNNs), are not expected to identify structural components\naccurately when the image is a close-up view, lacking contextual information\nregarding where on the structure the image originates. Inspired by the\nsignificant progress in video processing techniques, this study investigates\nautomated bridge component recognition using video data, where the information\nfrom the past frames is used to augment the understanding of the current frame.\nA new simulated video dataset is created to train the machine learning\nalgorithms. Then, convolutional Neural Networks (CNNs) with recurrent\narchitectures are designed and applied to implement the automated bridge\ncomponent recognition task. Results are presented for simulated video data, as\nwell as video collected in the field.\ndetails: "}, {"id": 3, "contents": "title: Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks\nauthors: Peter L. Bartlett,David P. Helmbold,Philip M. Long\nabstract: We analyze algorithms for approximating a function $f(x) = \\Phi x$ mapping\n$\\Re^d$ to $\\Re^d$ using deep linear neural networks, i.e. that learn a\nfunction $h$ parameterized by matrices $\\Theta_1,...,\\Theta_L$ and defined by\n$h(x) = \\Theta_L \\Theta_{L-1} ... \\Theta_1 x$. We focus on algorithms that\nlearn through gradient descent on the population quadratic loss in the case\nthat the distribution over the inputs is isotropic.\n  We provide polynomial bounds on the number of iterations for gradient descent\nto approximate the least squares matrix $\\Phi$, in the case where the initial\nhypothesis $\\Theta_1 = ... = \\Theta_L = I$ has excess loss bounded by a small\nenough constant. On the other hand, we show that gradient descent fails to\nconverge for $\\Phi$ whose distance from the identity is a larger constant, and\nwe show that some forms of regularization toward the identity in each layer do\nnot help.\n  If $\\Phi$ is symmetric positive definite, we show that an algorithm that\ninitializes $\\Theta_i = I$ learns an $\\epsilon$-approximation of $f$ using a\nnumber of updates polynomial in $L$, the condition number of $\\Phi$, and\n$\\log(d/\\epsilon)$. In contrast, we show that if the least squares matrix\n$\\Phi$ is symmetric and has a negative eigenvalue, then all members of a class\nof algorithms that perform gradient descent with identity initialization, and\noptionally regularize toward the identity in each layer, fail to converge.\n  We analyze an algorithm for the case that $\\Phi$ satisfies $u^{\\top} \\Phi u >\n0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:\none that maintains the invariant $u^{\\top} \\Theta_L \\Theta_{L-1} ... \\Theta_1 u\n> 0$ for all $u$, and another that \"balances\" $\\Theta_1, ..., \\Theta_L$ so that\nthey have the same singular values.\ndetails: "}, {"id": 4, "contents": "title: Temporal coherence-based self-supervised learning for laparoscopic workflow analysis\nauthors: Isabel Funke,Alexander Jenke,Sören Torge Mees,Jürgen Weitz,Stefanie Speidel,Sebastian Bodenstedt\nabstract: In order to provide the right type of assistance at the right time,\ncomputer-assisted surgery systems need context awareness. To achieve this,\nmethods for surgical workflow analysis are crucial. Currently, convolutional\nneural networks provide the best performance for video-based workflow analysis\ntasks. For training such networks, large amounts of annotated data are\nnecessary. However, collecting a sufficient amount of data is often costly,\ntime-consuming, and not always feasible. In this paper, we address this problem\nby presenting and comparing different approaches for self-supervised\npretraining of neural networks on unlabeled laparoscopic videos using temporal\ncoherence. We evaluate our pretrained networks on Cholec80, a publicly\navailable dataset for surgical phase segmentation, on which a maximum F1 score\nof 84.6 was reached. Furthermore, we were able to achieve an increase of the F1\nscore of up to 10 points when compared to a non-pretrained neural network.\ndetails: "}, {"id": 5, "contents": "title: Better Runtime Guarantees Via Stochastic Domination\nauthors: Benjamin Doerr\nabstract: Apart from few exceptions, the mathematical runtime analysis of evolutionary\nalgorithms is mostly concerned with expected runtimes. In this work, we argue\nthat stochastic domination is a notion that should be used more frequently in\nthis area. Stochastic domination allows to formulate much more informative\nperformance guarantees, it allows to decouple the algorithm analysis into the\ntrue algorithmic part of detecting a domination statement and the\nprobability-theoretical part of deriving the desired probabilistic guarantees\nfrom this statement, and it helps finding simpler and more natural proofs.\n  As particular results, we prove a fitness level theorem which shows that the\nruntime is dominated by a sum of independent geometric random variables, we\nprove the first tail bounds for several classic runtime problems, and we give a\nshort and natural proof for Witt's result that the runtime of any $(\\mu,p)$\nmutation-based algorithm on any function with unique optimum is subdominated by\nthe runtime of a variant of the \\oea on the \\onemax function.\n  As side-products, we determine the fastest unbiased (1+1) algorithm for the\n\\leadingones benchmark problem, both in the general case and when restricted to\nstatic mutation operators, and we prove a Chernoff-type tail bound for sums of\nindependent coupon collector distributions.\ndetails: "}, {"id": 6, "contents": "title: Scaling Neural Machine Translation\nauthors: Myle Ott,Sergey Edunov,David Grangier,Michael Auli\nabstract: Sequence to sequence learning models still require several days to reach\nstate of the art performance on large benchmark datasets using a single\nmachine. This paper shows that reduced precision and large batch training can\nspeedup training by nearly 5x on a single 8-GPU machine with careful tuning and\nimplementation. On WMT'14 English-German translation, we match the accuracy of\nVaswani et al. (2017) in under 5 hours when training on 8 GPUs and we obtain a\nnew state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We\nfurther improve these results to 29.8 BLEU by training on the much larger\nParacrawl dataset. On the WMT'14 English-French task, we obtain a\nstate-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.\ndetails: "}, {"id": 7, "contents": "title: Interpretable Almost Matching Exactly for Causal Inference\nauthors: Yameng Liu,Aw Dieng,Sudeepa Roy,Cynthia Rudin,Alexander Volfovsky\nabstract: We aim to create the highest possible quality of treatment-control matches for categorical data in the potential outcomes framework. Matching methods are heavily used in the social sciences due to their interpretability, but most matching methods do not pass basic sanity checks: they fail when irrelevant variables are introduced, and tend to be either computationally slow or produce low-quality matches. The method proposed in this work aims to match units on a weighted Hamming distance, taking into account the relative importance of the covariates; the algorithm aims to match units on as many relevant variables as possible. To do this, the algorithm creates a hierarchy of covariate combinations on which to match (similar to downward closure), in the process solving an optimization problem for each unit in order to construct the optimal matches. The algorithm uses a single dynamic program to solve all of the optimization problems simultaneously. Notable advantages of our method over existing matching procedures are its high-quality matches, versatility in handling different data distributions that may have irrelevant variables, and ability to handle missing data by matching on as many available covariates as possible.\ndetails: "}, {"id": 8, "contents": "title: Deep Spatiotemporal Representation of the Face for Automatic Pain Intensity Estimation\nauthors: Mohammad Tavakolian,Abdenour Hadid\nabstract: Automatic pain intensity assessment has a high value in disease diagnosis\napplications. Inspired by the fact that many diseases and brain disorders can\ninterrupt normal facial expression formation, we aim to develop a computational\nmodel for automatic pain intensity assessment from spontaneous and micro facial\nvariations. For this purpose, we propose a 3D deep architecture for dynamic\nfacial video representation. The proposed model is built by stacking several\nconvolutional modules where each module encompasses a 3D convolution kernel\nwith a fixed temporal depth, several parallel 3D convolutional kernels with\ndifferent temporal depths, and an average pooling layer. Deploying variable\ntemporal depths in the proposed architecture allows the model to effectively\ncapture a wide range of spatiotemporal variations on the faces. Extensive\nexperiments on the UNBC-McMaster Shoulder Pain Expression Archive database show\nthat our proposed model yields in a promising performance compared to the\nstate-of-the-art in automatic pain intensity estimation.\ndetails: "}, {"id": 9, "contents": "title: Robust inference on the average treatment effect using the outcome highly adaptive lasso\nauthors: Cheng Ju,David Benkeser,Mark J. Van Der Laan\nabstract: Many estimators of the average effect of a treatment on an outcome require estimation of the propensity score, the outcome regression, or both. It is often beneficial to utilize flexible techniques such as semiparametric regression or machine learning to estimate these quantities. However, optimal estimation of these regressions does not necessarily lead to optimal estimation of the average treatment effect, particularly in settings with strong instrumental variables. A recent proposal addressed these issues via the outcome-adaptive lasso, a penalized regression technique for estimating the propensity score that seeks to minimize the impact of instrumental variables on treatment effect estimators. However, a notable limitation of this approach is that its application is restricted to parametric models. We propose a more flexible alternative that we call the outcome highly adaptive lasso. We discuss large sample theory for this estimator and propose closed form confidence intervals based on the proposed estimator. We show via simulation that our method offers benefits over several popular approaches.\ndetails: "}, {"id": 10, "contents": "title: Consistent Individualized Feature Attribution for Tree Ensembles\nauthors: Scott M. Lundberg,Gabriel G. Erion,Su-In Lee\nabstract: A unified approach to explain the output of any machine learning model.\ndetails: "}, {"id": 11, "contents": "title: BinGAN: Learning Compact Binary Descriptors with a Regularized GAN\nauthors: Maciej Zieba,Piotr Semberecki,Tarek El-Gaaly,Tomasz Trzcinski\nabstract: In this paper, we propose a novel regularization method for Generative\nAdversarial Networks, which allows the model to learn discriminative yet\ncompact binary representations of image patches (image descriptors). We employ\nthe dimensionality reduction that takes place in the intermediate layers of the\ndiscriminator network and train binarized low-dimensional representation of the\npenultimate layer to mimic the distribution of the higher-dimensional preceding\nlayers. To achieve this, we introduce two loss terms that aim at: (i) reducing\nthe correlation between the dimensions of the binarized low-dimensional\nrepresentation of the penultimate layer i. e. maximizing joint entropy) and\n(ii) propagating the relations between the dimensions in the high-dimensional\nspace to the low-dimensional space. We evaluate the resulting binary image\ndescriptors on two challenging applications, image matching and retrieval, and\nachieve state-of-the-art results.\ndetails: "}, {"id": 12, "contents": "title: Multiscale Fisher's Independence Test for Multivariate Dependence\nauthors: Shai Gorsky,Li Ma\nabstract: Identifying dependency in multivariate data is a common inference task that arises in numerous applications. However, existing nonparametric independence tests typically require computation that scales at least quadratically with the sample size, making it difficult to apply them to massive data. Moreover, resampling is usually necessary to evaluate the statistical significance of the resulting test statistics at finite sample sizes, further worsening the computational burden. We introduce a scalable, resampling-free approach to testing the independence between two random vectors by breaking down the task into simple univariate tests of independence on a collection of 2x2 contingency tables constructed through sequential coarse-to-fine discretization of the sample space, transforming the inference task into a multiple testing problem that can be completed with almost linear complexity with respect to the sample size. To address increasing dimensionality, we introduce a coarse-to-fine sequential adaptive procedure that exploits the spatial features of dependency structures to more effectively examine the sample space. We derive a finite-sample theory that guarantees the inferential validity of our adaptive procedure at any given sample size. In particular, we show that our approach can achieve strong control of the family-wise error rate without resampling or large-sample approximation. We demonstrate the substantial computational advantage of the procedure in comparison to existing approaches as well as its decent statistical power under various dependency scenarios through an extensive simulation study, and illustrate how the divide-and-conquer nature of the procedure can be exploited to not just test independence but to learn the nature of the underlying dependency. Finally, we demonstrate the use of our method through analyzing a large data set from a flow cytometry experiment.\ndetails: "}, {"id": 13, "contents": "title: Kernel-based Outlier Detection using the Inverse Christoffel Function\nauthors: Armin Askari,Forest Yang,Laurent El Ghaoui\nabstract: Outlier detection methods have become increasingly relevant in recent years\ndue to increased security concerns and because of its vast application to\ndifferent fields. Recently, Pauwels and Lasserre (2016) noticed that the\nsublevel sets of the inverse Christoffel function accurately depict the shape\nof a cloud of data using a sum-of-squares polynomial and can be used to perform\noutlier detection. In this work, we propose a kernelized variant of the inverse\nChristoffel function that makes it computationally tractable for data sets with\na large number of features. We compare our approach to current methods on 15\ndifferent data sets and achieve the best average area under the precision\nrecall curve (AUPRC) score, the best average rank and the lowest root mean\nsquare deviation.\ndetails: "}, {"id": 14, "contents": "title: Kid-Net: Convolution Networks for Kidney Vessels Segmentation from CT-Volumes\nauthors: Ahmed Taha,Pechin Lo,Junning Li,Tao Zhao\nabstract: Semantic image segmentation plays an important role in modeling\npatient-specific anatomy. We propose a convolution neural network, called\nKid-Net, along with a training schema to segment kidney vessels: artery, vein\nand collecting system. Such segmentation is vital during the surgical planning\nphase in which medical decisions are made before surgical incision. Our main\ncontribution is developing a training schema that handles unbalanced data,\nreduces false positives and enables high-resolution segmentation with a limited\nmemory budget. These objectives are attained using dynamic weighting, random\nsampling and 3D patch segmentation. Manual medical image annotation is both\ntime-consuming and expensive. Kid-Net reduces kidney vessels segmentation time\nfrom matter of hours to minutes. It is trained end-to-end using 3D patches from\nvolumetric CT-images. A complete segmentation for a 512x512x512 CT-volume is\nobtained within a few minutes (1-2 mins) by stitching the output 3D patches\ntogether. Feature down-sampling and up-sampling are utilized to achieve higher\nclassification and localization accuracies. Quantitative and qualitative\nevaluation results on a challenging testing dataset show Kid-Net competence.\ndetails: "}, {"id": 15, "contents": "title: Modularity Matters: Learning Invariant Relational Reasoning Tasks\nauthors: Jason Jo,Vikas Verma,Yoshua Bengio\nabstract: We focus on two supervised visual reasoning tasks whose labels encode a\nsemantic relational rule between two or more objects in an image: the MNIST\nParity task and the colorized Pentomino task. The objects in the images undergo\nrandom translation, scaling, rotation and coloring transformations. Thus these\ntasks involve invariant relational reasoning. We report uneven performance of\nvarious deep CNN models on these two tasks. For the MNIST Parity task, we\nreport that the VGG19 model soundly outperforms a family of ResNet models.\nMoreover, the family of ResNet models exhibits a general sensitivity to random\ninitialization for the MNIST Parity task. For the colorized Pentomino task, now\nboth the VGG19 and ResNet models exhibit sluggish optimization and very poor\ntest generalization, hovering around 30% test error. The CNN we tested all\nlearn hierarchies of fully distributed features and thus encode the distributed\nrepresentation prior. We are motivated by a hypothesis from cognitive\nneuroscience which posits that the human visual cortex is modularized, and this\nallows the visual cortex to learn higher order invariances. To this end, we\nconsider a modularized variant of the ResNet model, referred to as a Residual\nMixture Network (ResMixNet) which employs a mixture-of-experts architecture to\ninterleave distributed representations with more specialized, modular\nrepresentations. We show that very shallow ResMixNets are capable of learning\neach of the two tasks well, attaining less than 2% and 1% test error on the\nMNIST Parity and the colorized Pentomino tasks respectively. Most importantly,\nthe ResMixNet models are extremely parameter efficient: generalizing better\nthan various non-modular CNNs that have over 10x the number of parameters.\nThese experimental results support the hypothesis that modularity is a robust\nprior for learning invariant relational reasoning.\ndetails: "}, {"id": 16, "contents": "title: Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks\nauthors: Jinghui Chen,Dongruo Zhou,Yiqi Tang,Ziyan Yang,Yuan Cao,Quanquan Gu\nabstract: Adaptive gradient methods, which adopt historical gradient information to automatically adjust the learning rate, despite the nice property of fast convergence, have been observed to generalize worse than stochastic gradient descent (SGD) with momentum in training deep neural networks. This leaves how to close the generalization gap of adaptive gradient methods an open problem. In this work, we show that adaptive gradient methods such as Adam, Amsgrad, are sometimes \"over adapted\". We design a new algorithm, called Partially adaptive momentum estimation method, which unifies the Adam/Amsgrad with SGD by introducing a partial adaptive parameter $p$, to achieve the best from both worlds. We also prove the convergence rate of our proposed algorithm to a stationary point in the stochastic nonconvex optimization setting. Experiments on standard benchmarks show that our proposed algorithm can maintain a fast convergence rate as Adam/Amsgrad while generalizing as well as SGD in training deep neural networks. These results would suggest practitioners pick up adaptive gradient methods once again for faster training of deep neural networks.\ndetails: "}, {"id": 17, "contents": "title: A Memory Network Approach for Story-based Temporal Summarization of 360° Videos\nauthors: Sang-ho Lee,Jinyoung Sung,Youngjae Yu,Gunhee Kim\nabstract: We address the problem of story-based temporal summarization of long\n360{\\deg} videos. We propose a novel memory network model named Past-Future\nMemory Network (PFMN), in which we first compute the scores of 81 normal field\nof view (NFOV) region proposals cropped from the input 360{\\deg} video, and\nthen recover a latent, collective summary using the network with two external\nmemories that store the embeddings of previously selected subshots and future\ncandidate subshots. Our major contributions are two-fold. First, our work is\nthe first to address story-based temporal summarization of 360{\\deg} videos.\nSecond, our model is the first attempt to leverage memory networks for video\nsummarization tasks. For evaluation, we perform three sets of experiments.\nFirst, we investigate the view selection capability of our model on the\nPano2Vid dataset. Second, we evaluate the temporal summarization with a newly\ncollected 360{\\deg} video dataset. Finally, we experiment our model's\nperformance in another domain, with image-based storytelling VIST dataset. We\nverify that our model achieves state-of-the-art performance on all the tasks.\ndetails: "}, {"id": 18, "contents": "title: POTs: Protective Optimization Technologies\nauthors: Bogdan Kulynych,Rebekah Overdorf,Carmela Troncoso,Seda Gürses\nabstract: Algorithmic fairness aims to address the economic, moral, social, and political impact that digital systems have on populations through solutions that can be applied by service providers. Fairness frameworks do so, in part, by mapping these problems to a narrow definition and assuming the service providers can be trusted to deploy countermeasures. Not surprisingly, these decisions limit fairness frameworks' ability to capture a variety of harms caused by systems. We characterize fairness limitations using concepts from requirements engineering and from social sciences. We show that the focus on algorithms' inputs and outputs misses harms that arise from systems interacting with the world; that the focus on bias and discrimination omits broader harms on populations and their environments; and that relying on service providers excludes scenarios where they are not cooperative or intentionally adversarial. We propose Protective Optimization Technologies (POTs). POTs provide means for affected parties to address the negative impacts of systems in the environment, expanding avenues for political contestation. POTs intervene from outside the system, do not require service providers to cooperate, and can serve to correct, shift, or expose harms that systems impose on populations and their environments. We illustrate the potential and limitations of POTs in two case studies: countering road congestion caused by traffic-beating applications, and recalibrating credit scoring for loan applicants.\ndetails: "}, {"id": 19, "contents": "title: Surface Networks\nauthors: Ilya Kostrikov,Zhongshi Jiang,Daniele Panozzo,Denis Zorin,Joan Bruna\nabstract: We study data-driven representations for three-dimensional triangle meshes,\nwhich are one of the prevalent objects used to represent 3D geometry. Recent\nworks have developed models that exploit the intrinsic geometry of manifolds\nand graphs, namely the Graph Neural Networks (GNNs) and its spectral variants,\nwhich learn from the local metric tensor via the Laplacian operator. Despite\noffering excellent sample complexity and built-in invariances, intrinsic\ngeometry alone is invariant to isometric deformations, making it unsuitable for\nmany applications. To overcome this limitation, we propose several upgrades to\nGNNs to leverage extrinsic differential geometry properties of\nthree-dimensional surfaces, increasing its modeling power.\n  In particular, we propose to exploit the Dirac operator, whose spectrum\ndetects principal curvature directions --- this is in stark contrast with the\nclassical Laplace operator, which directly measures mean curvature. We coin the\nresulting models \\emph{Surface Networks (SN)}. We prove that these models\ndefine shape representations that are stable to deformation and to\ndiscretization, and we demonstrate the efficiency and versatility of SNs on two\nchallenging tasks: temporal prediction of mesh deformations under non-linear\ndynamics and generative models using a variational autoencoder framework with\nencoders/decoders given by SNs.\ndetails: "}, {"id": 20, "contents": "title: Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples\nauthors: Gail Weiss,Yoav Goldberg,Eran Yahav\nabstract: We present a novel algorithm that uses exact learning and abstraction to extract a deterministic finite automaton describing the state dynamics of a given trained RNN. We do this using Angluin's L* algorithm as a learner and the trained RNN as an oracle. Our technique efficiently extracts accurate automata from trained RNNs, even when the state vectors are large and require fine differentiation.\ndetails: "}, {"id": 21, "contents": "title: Unsupervised Word Segmentation from Speech with Attention\nauthors: Pierre Godard,Marcely Zanon-Boito,Lucas Ondel,Alexandre Berard,François Yvon,Aline Villavicencio,Laurent Besacier\nabstract: We present a first attempt to perform attentional word segmentation directly\nfrom the speech signal, with the final goal to automatically identify lexical\nunits in a low-resource, unwritten language (UL). Our methodology assumes a\npairing between recordings in the UL with translations in a well-resourced\nlanguage. It uses Acoustic Unit Discovery (AUD) to convert speech into a\nsequence of pseudo-phones that is segmented using neural soft-alignments\nproduced by a neural machine translation model. Evaluation uses an actual Bantu\nUL, Mboshi; comparisons to monolingual and bilingual baselines illustrate the\npotential of attentional word segmentation for language documentation.\ndetails: "}, {"id": 22, "contents": "title: Semantically Selective Augmentation for Deep Compact Person Re-Identification\nauthors: Víctor Ponce-López,Tilo Burghardt,Sion Hannunna,Dima Damen,Alessandro Masullo,Majid Mirmehdi\nabstract: We present a deep person re-identification approach that combines\nsemantically selective, deep data augmentation with clustering-based network\ncompression to generate high performance, light and fast inference networks. In\nparticular, we propose to augment limited training data via sampling from a\ndeep convolutional generative adversarial network (DCGAN), whose discriminator\nis constrained by a semantic classifier to explicitly control the domain\nspecificity of the generation process. Thereby, we encode information in the\nclassifier network which can be utilized to steer adversarial synthesis, and\nwhich fuels our CondenseNet ID-network training. We provide a quantitative and\nqualitative analysis of the approach and its variants on a number of datasets,\nobtaining results that outperform the state-of-the-art on the LIMA dataset for\nlong-term monitoring in indoor living spaces.\ndetails: "}, {"id": 23, "contents": "title: Assessing robustness of radiomic features by image perturbation\nauthors: Alex Zwanenburg,Stefan Leger,Linda Agolli,Karoline Pilz,Esther G. C. Troost,Christian Richter,Steffen Löck\nabstract: Image features need to be robust against differences in positioning,\nacquisition and segmentation to ensure reproducibility. Radiomic models that\nonly include robust features can be used to analyse new images, whereas models\nwith non-robust features may fail to predict the outcome of interest\naccurately. Test-retest imaging is recommended to assess robustness, but may\nnot be available for the phenotype of interest. We therefore investigated 18\nmethods to determine feature robustness based on image perturbations.\nTest-retest and perturbation robustness were compared for 4032 features that\nwere computed from the gross tumour volume in two cohorts with computed\ntomography imaging: I) 31 non-small-cell lung cancer (NSCLC) patients; II): 19\nhead-and-neck squamous cell carcinoma (HNSCC) patients. Robustness was measured\nusing the intraclass correlation coefficient (1,1) (ICC). Features with\nICC$\\geq0.90$ were considered robust. The NSCLC cohort contained more robust\nfeatures for test-retest imaging than the HNSCC cohort ($73.5\\%$ vs. $34.0\\%$).\nA perturbation chain consisting of noise addition, affine translation, volume\ngrowth/shrinkage and supervoxel-based contour randomisation identified the\nfewest false positive robust features (NSCLC: $3.3\\%$; HNSCC: $10.0\\%$). Thus,\nthis perturbation chain may be used to assess feature robustness.\ndetails: "}, {"id": 24, "contents": "title: ReConvNet: Video Object Segmentation with Spatio-Temporal Features Modulation\nauthors: Francesco Lattari,Marco Ciccone,Matteo Matteucci,Jonathan Masci,Francesco Visin\nabstract: We introduce ReConvNet, a recurrent convolutional architecture for\nsemi-supervised video object segmentation that is able to fast adapt its\nfeatures to focus on any specific object of interest at inference time.\nGeneralization to new objects never observed during training is known to be a\nhard task for supervised approaches that would need to be retrained. To tackle\nthis problem, we propose a more efficient solution that learns spatio-temporal\nfeatures self-adapting to the object of interest via conditional affine\ntransformations. This approach is simple, can be trained end-to-end and does\nnot necessarily require extra training steps at inference time. Our method\nshows competitive results on DAVIS2016 with respect to state-of-the art\napproaches that use online fine-tuning, and outperforms them on DAVIS2017.\nReConvNet shows also promising results on the DAVIS-Challenge 2018 winning the\n$10$-th position.\ndetails: "}, {"id": 25, "contents": "title: Tree Edit Distance Learning via Adaptive Symbol Embeddings\nauthors: Benjamin Paaßen,Claudio Gallicchio,Alessio Micheli,Barbara Hammer\nabstract: Metric learning has the aim to improve classification accuracy by learning a\ndistance measure which brings data points from the same class closer together\nand pushes data points from different classes further apart. Recent research\nhas demonstrated that metric learning approaches can also be applied to trees,\nsuch as molecular structures, abstract syntax trees of computer programs, or\nsyntax trees of natural language, by learning the cost function of an edit\ndistance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.\nHowever, learning such costs directly may yield an edit distance which violates\nmetric axioms, is challenging to interpret, and may not generalize well. In\nthis contribution, we propose a novel metric learning approach for trees which\nwe call embedding edit distance learning (BEDL) and which learns an edit\ndistance indirectly by embedding the tree nodes as vectors, such that the\nEuclidean distance between those vectors supports class discrimination. We\nlearn such embeddings by reducing the distance to prototypical trees from the\nsame class and increasing the distance to prototypical trees from different\nclasses. In our experiments, we show that BEDL improves upon the\nstate-of-the-art in metric learning for trees on six benchmark data sets,\nranging from computer science over biomedical data to a natural-language\nprocessing data set containing over 300,000 nodes.\ndetails: "}, {"id": 26, "contents": "title: Towards multi-instrument drum transcription\nauthors: Richard Vogl,Gerhard Widmer,Peter Knees\nabstract: Automatic drum transcription, a subtask of the more general automatic music\ntranscription, deals with extracting drum instrument note onsets from an audio\nsource. Recently, progress in transcription performance has been made using\nnon-negative matrix factorization as well as deep learning methods. However,\nthese works primarily focus on transcribing three drum instruments only: snare\ndrum, bass drum, and hi-hat. Yet, for many applications, the ability to\ntranscribe more drum instruments which make up standard drum kits used in\nwestern popular music would be desirable. In this work, convolutional and\nconvolutional recurrent neural networks are trained to transcribe a wider range\nof drum instruments. First, the shortcomings of publicly available datasets in\nthis context are discussed. To overcome these limitations, a larger synthetic\ndataset is introduced. Then, methods to train models using the new dataset\nfocusing on generalization to real world data are investigated. Finally, the\ntrained models are evaluated on publicly available datasets and results are\ndiscussed. The contributions of this work comprise: (i.) a large-scale\nsynthetic dataset for drum transcription, (ii.) first steps towards an\nautomatic drum transcription system that supports a larger range of instruments\nby evaluating and discussing training setups and the impact of datasets in this\ncontext, and (iii.) a publicly available set of trained models for drum\ntranscription. Additional materials are available at\nhttp://ifs.tuwien.ac.at/~vogl/dafx2018\ndetails: "}, {"id": 27, "contents": "title: Subword and Crossword Units for CTC Acoustic Models\nauthors: Thomas Zenkel,Ramon Sanabria,Florian Metze,Alex Waibel\nabstract: This paper proposes a novel approach to create an unit set for CTC based\nspeech recognition systems. By using Byte Pair Encoding we learn an unit set of\nan arbitrary size on a given training text. In contrast to using characters or\nwords as units this allows us to find a good trade-off between the size of our\nunit set and the available training data. We evaluate both Crossword units,\nthat may span multiple word, and Subword units. By combining this approach with\ndecoding methods using a separate language model we are able to achieve state\nof the art results for grapheme based CTC systems.\ndetails: "}, {"id": 28, "contents": "title: Cardinality Leap for Open-Ended Evolution: Theoretical Consideration and Demonstration by \"Hash Chemistry\"\nauthors: Hiroki Sayama\nabstract: Open-ended evolution requires unbounded possibilities that evolving entities\ncan explore. The cardinality of a set of those possibilities thus has a\nsignificant implication for the open-endedness of evolution. We propose that\nfacilitating formation of higher-order entities is a generalizable, effective\nway to cause a \"cardinality leap\" in the set of possibilities that promotes\nopen-endedness. We demonstrate this idea with a simple, proof-of-concept toy\nmodel called \"Hash Chemistry\" that uses a hash function as a fitness evaluator\nof evolving entities of any size/order. Simulation results showed that the\ncumulative number of unique replicating entities that appeared in evolution\nincreased almost linearly along time without an apparent bound, demonstrating\nthe effectiveness of the proposed cardinality leap. It was also observed that\nthe number of individual entities involved in a single replication event\ngradually increased over time, indicating evolutionary appearance of\nhigher-order entities. Moreover, these behaviors were not observed in control\nexperiments in which fitness evaluators were replaced by random number\ngenerators. This strongly suggests that the dynamics observed in Hash Chemistry\nwere indeed evolutionary behaviors driven by selection and adaptation taking\nplace at multiple scales.\ndetails: "}, {"id": 29, "contents": "title: Learning Asymmetric and Local Features in Multi-Dimensional Data through Wavelets with Recursive Partitioning\nauthors: Meng Li,Li Ma\nabstract: Effective learning of asymmetric and local features in images and other data observed on multi-dimensional grids is a challenging objective critical for a wide range of image processing applications involving biomedical and natural images. It requires methods that are sensitive to local details while fast enough to handle massive numbers of images of ever increasing sizes. We introduce a probabilistic model-based framework that achieves these objectives by incorporating adaptivity into discrete wavelet transforms (DWT) through Bayesian hierarchical modeling, thereby allowing wavelet bases to adapt to the geometric structure of the data while maintaining the high computational scalability of wavelet methods---linear in the sample size (e.g., the resolution of an image). We derive a recursive representation of the Bayesian posterior model which leads to an exact message passing algorithm to complete learning and inference. While our framework is applicable to a range of problems including multi-dimensional signal processing, compression, and structural learning, we illustrate its work and evaluate its performance in the context of image reconstruction using real images from the ImageNet database, two widely used benchmark datasets, and a dataset from retinal optical coherence tomography and compare its performance to state-of-the-art methods based on basis transforms and deep learning.\ndetails: "}, {"id": 30, "contents": "title: On Enhancing Speech Emotion Recognition using Generative Adversarial Networks\nauthors: Saurabh Sahu,Rahul Gupta,Carol Espy-Wilson\nabstract: Generative Adversarial Networks (GANs) have gained a lot of attention from\nmachine learning community due to their ability to learn and mimic an input\ndata distribution. GANs consist of a discriminator and a generator working in\ntandem playing a min-max game to learn a target underlying data distribution;\nwhen fed with data-points sampled from a simpler distribution (like uniform or\nGaussian distribution). Once trained, they allow synthetic generation of\nexamples sampled from the target distribution. We investigate the application\nof GANs to generate synthetic feature vectors used for speech emotion\nrecognition. Specifically, we investigate two set ups: (i) a vanilla GAN that\nlearns the distribution of a lower dimensional representation of the actual\nhigher dimensional feature vector and, (ii) a conditional GAN that learns the\ndistribution of the higher dimensional feature vectors conditioned on the\nlabels or the emotional class to which it belongs. As a potential practical\napplication of these synthetically generated samples, we measure any\nimprovement in a classifier's performance when the synthetic data is used along\nwith real data for training. We perform cross-validation analyses followed by a\ncross-corpus study.\ndetails: "}, {"id": 31, "contents": "title: Banach Wasserstein GAN\nauthors: Jonas Adler,Sebastian Lunz\nabstract: Wasserstein Generative Adversarial Networks (WGANs) can be used to generate\nrealistic samples from complicated image distributions. The Wasserstein metric\nused in WGANs is based on a notion of distance between individual images, which\ninduces a notion of distance between probability distributions of images. So\nfar the community has considered $\\ell^2$ as the underlying distance. We\ngeneralize the theory of WGAN with gradient penalty to Banach spaces, allowing\npractitioners to select the features to emphasize in the generator. We further\ndiscuss the effect of some particular choices of underlying norms, focusing on\nSobolev norms. Finally, we demonstrate a boost in performance for an\nappropriate choice of norm on CIFAR-10 and CelebA.\ndetails: "}, {"id": 32, "contents": "title: Comparison-Based Random Forests\nauthors: Siavash Haghiri,Damien Garreau,Ulrike Von Luxburg\nabstract: Assume we are given a set of items from a general metric space, but we\nneither have access to the representation of the data nor to the distances\nbetween data points. Instead, suppose that we can actively choose a triplet of\nitems (A,B,C) and ask an oracle whether item A is closer to item B or to item\nC. In this paper, we propose a novel random forest algorithm for regression and\nclassification that relies only on such triplet comparisons. In the theory part\nof this paper, we establish sufficient conditions for the consistency of such a\nforest. In a set of comprehensive experiments, we then demonstrate that the\nproposed random forest is efficient both for classification and regression. In\nparticular, it is even competitive with other methods that have direct access\nto the metric representation of the data.\ndetails: "}, {"id": 33, "contents": "title: On Multi-resident Activity Recognition in Ambient Smart-Homes\nauthors: Son N. Tran,Qing Zhang,Mohan Karunanithi\nabstract: Increasing attention to the research on activity monitoring in smart homes\nhas motivated the employment of ambient intelligence to reduce the deployment\ncost and solve the privacy issue. Several approaches have been proposed for\nmulti-resident activity recognition, however, there still lacks a comprehensive\nbenchmark for future research and practical selection of models. In this paper\nwe study different methods for multi-resident activity recognition and evaluate\nthem on same sets of data. The experimental results show that recurrent neural\nnetwork with gated recurrent units is better than other models and also\nconsiderably efficient, and that using combined activities as single labels is\nmore effective than represent them as separate labels.\ndetails: "}, {"id": 34, "contents": "title: Evaluating and Characterizing Incremental Learning from Non-Stationary Data\nauthors: Alejandro Cervantes,Christian Gagné,Pedro Isasi,Marc Parizeau\nabstract: Incremental learning from non-stationary data poses special challenges to the\nfield of machine learning. Although new algorithms have been developed for\nthis, assessment of results and comparison of behaviors are still open\nproblems, mainly because evaluation metrics, adapted from more traditional\ntasks, can be ineffective in this context. Overall, there is a lack of common\ntesting practices. This paper thus presents a testbed for incremental\nnon-stationary learning algorithms, based on specially designed synthetic\ndatasets. Also, test results are reported for some well-known algorithms to\nshow that the proposed methodology is effective at characterizing their\nstrengths and weaknesses. It is expected that this methodology will provide a\ncommon basis for evaluating future contributions in the field.\ndetails: "}, {"id": 35, "contents": "title: Quantized Compressive K-Means\nauthors: Vincent Schellekens,Laurent Jacques\nabstract: The recent framework of compressive statistical learning aims at designing\ntractable learning algorithms that use only a heavily compressed\nrepresentation-or sketch-of massive datasets. Compressive K-Means (CKM) is such\na method: it estimates the centroids of data clusters from pooled, non-linear,\nrandom signatures of the learning examples. While this approach significantly\nreduces computational time on very large datasets, its digital implementation\nwastes acquisition resources because the learning examples are compressed only\nafter the sensing stage. The present work generalizes the sketching procedure\ninitially defined in Compressive K-Means to a large class of periodic\nnonlinearities including hardware-friendly implementations that compressively\nacquire entire datasets. This idea is exemplified in a Quantized Compressive\nK-Means procedure, a variant of CKM that leverages 1-bit universal quantization\n(i.e. retaining the least significant bit of a standard uniform quantizer) as\nthe periodic sketch nonlinearity. Trading for this resource-efficient signature\n(standard in most acquisition schemes) has almost no impact on the clustering\nperformances, as illustrated by numerical experiments.\ndetails: "}, {"id": 36, "contents": "title: Self-Attentional Acoustic Models\nauthors: Matthias Sperber,Jan Niehues,Graham Neubig,Sebastian Stüker,Alex Waibel\nabstract: Self-attention is a method of encoding sequences of vectors by relating these\nvectors to each-other based on pairwise similarities. These models have\nrecently shown promising results for modeling discrete sequences, but they are\nnon-trivial to apply to acoustic modeling due to computational and modeling\nissues. In this paper, we apply self-attention to acoustic modeling, proposing\nseveral improvements to mitigate these issues: First, self-attention memory\ngrows quadratically in the sequence length, which we address through a\ndownsampling technique. Second, we find that previous approaches to incorporate\nposition information into the model are unsuitable and explore other\nrepresentations and hybrid models to this end. Third, to stress the importance\nof local context in the acoustic signal, we propose a Gaussian biasing approach\nthat allows explicit control over the context range. Experiments find that our\nmodel approaches a strong baseline based on LSTMs with network-in-network\nconnections while being much faster to compute. Besides speed, we find that\ninterpretability is a strength of self-attentional acoustic models, and\ndemonstrate that self-attention heads learn a linguistically plausible division\nof labor.\ndetails: "}, {"id": 37, "contents": "title: Snap ML: A Hierarchical Framework for Machine Learning\nauthors: Celestine Dünner,Thomas Parnell,Dimitrios Sarigiannis,Nikolas Ioannou,Andreea Anghel,Gummadi Ravi,Madhusudanan Kandasamy,Haralampos Pozidis\nabstract: We describe a new software framework for fast training of generalized linear\nmodels. The framework, named Snap Machine Learning (Snap ML), combines recent\nadvances in machine learning systems and algorithms in a nested manner to\nreflect the hierarchical architecture of modern computing systems. We prove\ntheoretically that such a hierarchical system can accelerate training in\ndistributed environments where intra-node communication is cheaper than\ninter-node communication. Additionally, we provide a review of the\nimplementation of Snap ML in terms of GPU acceleration, pipelining,\ncommunication patterns and software architecture, highlighting aspects that\nwere critical for achieving high performance. We evaluate the performance of\nSnap ML in both single-node and multi-node environments, quantifying the\nbenefit of the hierarchical scheme and the data streaming functionality, and\ncomparing with other widely-used machine learning software frameworks. Finally,\nwe present a logistic regression benchmark on the Criteo Terabyte Click Logs\ndataset and show that Snap ML achieves the same test loss an order of magnitude\nfaster than any of the previously reported results, including those obtained\nusing TensorFlow and scikit-learn.\ndetails: "}, {"id": 38, "contents": "title: Multilingual bottleneck features for subword modeling in zero-resource languages\nauthors: Enno Hermann,Sharon Goldwater\nabstract: How can we effectively develop speech technology for languages where no\ntranscribed data is available? Many existing approaches use no annotated\nresources at all, yet it makes sense to leverage information from large\nannotated corpora in other languages, for example in the form of multilingual\nbottleneck features (BNFs) obtained from a supervised speech recognition\nsystem. In this work, we evaluate the benefits of BNFs for subword modeling\n(feature extraction) in six unseen languages on a word discrimination task.\nFirst we establish a strong unsupervised baseline by combining two existing\nmethods: vocal tract length normalisation (VTLN) and the correspondence\nautoencoder (cAE). We then show that BNFs trained on a single language already\nbeat this baseline; including up to 10 languages results in additional\nimprovements which cannot be matched by just adding more data from a single\nlanguage. Finally, we show that the cAE can improve further on the BNFs if\nhigh-quality same-word pairs are available.\ndetails: "}, {"id": 39, "contents": "title: Learning to Write Stylized Chinese Characters by Reading a Handful of Examples\nauthors: Danyang Sun,Tongzheng Ren,Chongxun Li,Hang Su,Jun Zhu\nabstract: Automatically writing stylized Chinese characters is an attractive yet\nchallenging task due to its wide applicabilities. In this paper, we propose a\nnovel framework named Style-Aware Variational Auto-Encoder (SA-VAE) to flexibly\ngenerate Chinese characters. Specifically, we propose to capture the different\ncharacteristics of a Chinese character by disentangling the latent features\ninto content-related and style-related components. Considering of the complex\nshapes and structures, we incorporate the structure information as prior\nknowledge into our framework to guide the generation. Our framework shows a\npowerful one-shot/low-shot generalization ability by inferring the style\ncomponent given a character with unseen style. To the best of our knowledge,\nthis is the first attempt to learn to write new-style Chinese characters by\nobserving only one or a few examples. Extensive experiments demonstrate its\neffectiveness in generating different stylized Chinese characters by fusing the\nfeature vectors corresponding to different contents and styles, which is of\nsignificant importance in real-world applications.\ndetails: "}, {"id": 40, "contents": "title: iPose: Instance-Aware 6D Pose Estimation of Partly Occluded Objects\nauthors: Omid Hosseini Jafari,Siva Karthik Mustikovela,Karl Pertsch,Eric Brachmann,Carsten Rother\nabstract: We address the task of 6D pose estimation of known rigid objects from single\ninput images in scenarios where the objects are partly occluded. Recent\nRGB-D-based methods are robust to moderate degrees of occlusion. For RGB\ninputs, no previous method works well for partly occluded objects. Our main\ncontribution is to present the first deep learning-based system that estimates\naccurate poses for partly occluded objects from RGB-D and RGB input. We achieve\nthis with a new instance-aware pipeline that decomposes 6D object pose\nestimation into a sequence of simpler steps, where each step removes specific\naspects of the problem. The first step localizes all known objects in the image\nusing an instance segmentation network, and hence eliminates surrounding\nclutter and occluders. The second step densely maps pixels to 3D object surface\npositions, so called object coordinates, using an encoder-decoder network, and\nhence eliminates object appearance. The third, and final, step predicts the 6D\npose using geometric optimization. We demonstrate that we significantly\noutperform the state-of-the-art for pose estimation of partly occluded objects\nfor both RGB and RGB-D input.\ndetails: "}, {"id": 41, "contents": "title: Uncertainty in multitask learning: joint representations for probabilistic MR-only radiotherapy planning\nauthors: Felix J. S. Bragman,Ryutaro Tanno,Zach Eaton-Rosen,Wenqi Li,David J. Hawkes,Sebastien Ourselin,Daniel C. Alexander,Jamie R. McClelland,M. Jorge Cardoso\nabstract: Multi-task neural network architectures provide a mechanism that jointly\nintegrates information from distinct sources. It is ideal in the context of\nMR-only radiotherapy planning as it can jointly regress a synthetic CT (synCT)\nscan and segment organs-at-risk (OAR) from MRI. We propose a probabilistic\nmulti-task network that estimates: 1) intrinsic uncertainty through a\nheteroscedastic noise model for spatially-adaptive task loss weighting and 2)\nparameter uncertainty through approximate Bayesian inference. This allows\nsampling of multiple segmentations and synCTs that share their network\nrepresentation. We test our model on prostate cancer scans and show that it\nproduces more accurate and consistent synCTs with a better estimation in the\nvariance of the errors, state of the art results in OAR segmentation and a\nmethodology for quality assurance in radiotherapy treatment planning.\ndetails: "}, {"id": 42, "contents": "title: Deep Recurrent Neural Network for Multi-target Filtering\nauthors: Mehryar Emambakhsh,Alessandro Bay,Eduard Vazquez\nabstract: This paper addresses the problem of fixed motion and measurement models for\nmulti-target filtering using an adaptive learning framework. This is performed\nby defining target tuples with random finite set terminology and utilisation of\nrecurrent neural networks with a long short-term memory architecture. A novel\ndata association algorithm compatible with the predicted tracklet tuples is\nproposed, enabling the update of occluded targets, in addition to assigning\nbirth, survival and death of targets. The algorithm is evaluated over a\ncommonly used filtering simulation scenario, with highly promising results.\ndetails: "}, {"id": 43, "contents": "title: Low-Resource Speech-to-Text Translation\nauthors: Sameer Bansal,Herman Kamper,Karen Livescu,Adam Lopez,Sharon Goldwater\nabstract: Speech-to-text translation has many potential applications for low-resource\nlanguages, but the typical approach of cascading speech recognition with\nmachine translation is often impossible, since the transcripts needed to train\na speech recognizer are usually not available for low-resource languages.\nRecent work has found that neural encoder-decoder models can learn to directly\ntranslate foreign speech in high-resource scenarios, without the need for\nintermediate transcription. We investigate whether this approach also works in\nsettings where both data and computation are limited. To make the approach\nefficient, we make several architectural changes, including a change from\ncharacter-level to word-level decoding. We find that this choice yields crucial\nspeed improvements that allow us to train with fewer computational resources,\nyet still performs well on frequent words. We explore models trained on between\n20 and 160 hours of data, and find that although models trained on less data\nhave considerably lower BLEU scores, they can still predict words with\nrelatively high precision and recall---around 50% for a model trained on 50\nhours of data, versus around 60% for the full 160 hour model. Thus, they may\nstill be useful for some low-resource scenarios.\ndetails: "}, {"id": 44, "contents": "title: Computational Theories of Curiosity-Driven Learning\nauthors: Pierre-Yves Oudeyer\nabstract: What are the functions of curiosity? What are the mechanisms of\ncuriosity-driven learning? We approach these questions about the living using\nconcepts and tools from machine learning and developmental robotics. We argue\nthat curiosity-driven learning enables organisms to make discoveries to solve\ncomplex problems with rare or deceptive rewards. By fostering exploration and\ndiscovery of a diversity of behavioural skills, and ignoring these rewards,\ncuriosity can be efficient to bootstrap learning when there is no information,\nor deceptive information, about local improvement towards these problems. We\nalso explain the key role of curiosity for efficient learning of world models.\nWe review both normative and heuristic computational frameworks used to\nunderstand the mechanisms of curiosity in humans, conceptualizing the child as\na sense-making organism. These frameworks enable us to discuss the\nbi-directional causal links between curiosity and learning, and to provide new\nhypotheses about the fundamental role of curiosity in self-organizing\ndevelopmental structures through curriculum learning. We present various\ndevelopmental robotics experiments that study these mechanisms in action, both\nsupporting these hypotheses to understand better curiosity in humans and\nopening new research avenues in machine learning and artificial intelligence.\nFinally, we discuss challenges for the design of experimental paradigms for\nstudying curiosity in psychology and cognitive neuroscience.\n  Keywords: Curiosity, intrinsic motivation, lifelong learning, predictions,\nworld model, rewards, free-energy principle, learning progress, machine\nlearning, AI, developmental robotics, development, curriculum learning,\nself-organization.\ndetails: "}, {"id": 45, "contents": "title: Nonparametric Topic Modeling with Neural Inference\nauthors: Xuefei Ning,Yin Zheng,Zhuxi Jiang,Yu Wang,Huazhong Yang,Junzhou Huang\nabstract: This work focuses on combining nonparametric topic models with Auto-Encoding\nVariational Bayes (AEVB). Specifically, we first propose iTM-VAE, where the\ntopics are treated as trainable parameters and the document-specific topic\nproportions are obtained by a stick-breaking construction. The inference of\niTM-VAE is modeled by neural networks such that it can be computed in a simple\nfeed-forward manner. We also describe how to introduce a hyper-prior into\niTM-VAE so as to model the uncertainty of the prior parameter. Actually, the\nhyper-prior technique is quite general and we show that it can be applied to\nother AEVB based models to alleviate the {\\it collapse-to-prior} problem\nelegantly. Moreover, we also propose HiTM-VAE, where the document-specific\ntopic distributions are generated in a hierarchical manner. HiTM-VAE is even\nmore flexible and can generate topic distributions with better variability.\nExperimental results on 20News and Reuters RCV1-V2 datasets show that the\nproposed models outperform the state-of-the-art baselines significantly. The\nadvantages of the hyper-prior technique and the hierarchical model construction\nare also confirmed by experiments.\ndetails: "}, {"id": 46, "contents": "title: WSD algorithm based on a new method of vector-word contexts proximity calculation via epsilon-filtration\nauthors: Alexander Kirillov,Natalia Krizhanovsky,Andrew Krizhanovsky\nabstract: The problem of word sense disambiguation (WSD) is considered in the article.\nGiven a set of synonyms (synsets) and sentences with these synonyms. It is\nnecessary to select the meaning of the word in the sentence automatically. 1285\nsentences were tagged by experts, namely, one of the dictionary meanings was\nselected by experts for target words. To solve the WSD-problem, an algorithm\nbased on a new method of vector-word contexts proximity calculation is\nproposed. In order to achieve higher accuracy, a preliminary epsilon-filtering\nof words is performed, both in the sentence and in the set of synonyms. An\nextensive program of experiments was carried out. Four algorithms are\nimplemented, including a new algorithm. Experiments have shown that in a number\nof cases the new algorithm shows better results. The developed software and the\ntagged corpus have an open license and are available online. Wiktionary and\nWikisource are used. A brief description of this work can be viewed in slides\n(https://goo.gl/9ak6Gt). Video lecture in Russian on this research is available\nonline (https://youtu.be/-DLmRkepf58).\ndetails: "}, {"id": 47, "contents": "title: The Kanerva Machine: A Generative Distributed Memory\nauthors: Yan Wu,Greg Wayne,Alex Graves,Timothy Lillicrap\nabstract: We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train.\ndetails: "}, {"id": 48, "contents": "title: RenderNet: A deep convolutional network for differentiable rendering from 3D shapes\nauthors: Thu Nguyen-Phuoc,Chuan Li,Stephen Balaban,Yong-Liang Yang\nabstract: Traditional computer graphics rendering pipeline is designed for procedurally\ngenerating 2D quality images from 3D shapes with high performance. The\nnon-differentiability due to discrete operations such as visibility computation\nmakes it hard to explicitly correlate rendering parameters and the resulting\nimage, posing a significant challenge for inverse rendering tasks. Recent work\non differentiable rendering achieves differentiability either by designing\nsurrogate gradients for non-differentiable operations or via an approximate but\ndifferentiable renderer. These methods, however, are still limited when it\ncomes to handling occlusion, and restricted to particular rendering effects. We\npresent RenderNet, a differentiable rendering convolutional network with a\nnovel projection unit that can render 2D images from 3D shapes. Spatial\nocclusion and shading calculation are automatically encoded in the network. Our\nexperiments show that RenderNet can successfully learn to implement different\nshaders, and can be used in inverse rendering tasks to estimate shape, pose,\nlighting and texture from a single image.\ndetails: "}, {"id": 49, "contents": "title: Distributed learning with compressed gradients\nauthors: Sarit Khirirat,Hamid Reza Feyzmahdavian,Mikael Johansson\nabstract: Asynchronous computation and gradient compression have emerged as two key\ntechniques for achieving scalability in distributed optimization for\nlarge-scale machine learning. This paper presents a unified analysis framework\nfor distributed gradient methods operating with staled and compressed\ngradients. Non-asymptotic bounds on convergence rates and information exchange\nare derived for several optimization algorithms. These bounds give explicit\nexpressions for step-sizes and characterize how the amount of asynchrony and\nthe compression accuracy affect iteration and communication complexity\nguarantees. Numerical results highlight convergence properties of different\ngradient compression algorithms and confirm that fast convergence under limited\ninformation exchange is indeed possible.\ndetails: "}, {"id": 50, "contents": "title: SubGram: Extending Skip-gram Word Representation with Substrings\nauthors: Tom Kocmi,Ondřej Bojar\nabstract: Skip-gram (word2vec) is a recent method for creating vector representations\nof words (\"distributed word representations\") using a neural network. The\nrepresentation gained popularity in various areas of natural language\nprocessing, because it seems to capture syntactic and semantic information\nabout words without any explicit supervision in this respect. We propose\nSubGram, a refinement of the Skip-gram model to consider also the word\nstructure during the training process, achieving large gains on the Skip-gram\noriginal test set.\ndetails: "}, {"id": 51, "contents": "title: Learning from Outside the Viability Kernel: Why we Should Build Robots that can Fall with Grace\nauthors: Steve Heim,Alexander Spröwitz\nabstract: Despite impressive results using reinforcement learning to solve complex\nproblems from scratch, in robotics this has still been largely limited to\nmodel-based learning with very informative reward functions. One of the major\nchallenges is that the reward landscape often has large patches with no\ngradient, making it difficult to sample gradients effectively. We show here\nthat the robot state-initialization can have a more important effect on the\nreward landscape than is generally expected. In particular, we show the\ncounter-intuitive benefit of including initializations that are unviable, in\nother words initializing in states that are doomed to fail.\ndetails: "}, {"id": 52, "contents": "title: ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing\nauthors: Jian Zhang,Bernard Ghanem\nabstract: With the aim of developing a fast yet accurate algorithm for compressive\nsensing (CS) reconstruction of natural images, we combine in this paper the\nmerits of two existing categories of CS methods: the structure insights of\ntraditional optimization-based methods and the speed of recent network-based\nones. Specifically, we propose a novel structured deep network, dubbed\nISTA-Net, which is inspired by the Iterative Shrinkage-Thresholding Algorithm\n(ISTA) for optimizing a general $\\ell_1$ norm CS reconstruction model. To cast\nISTA into deep network form, we develop an effective strategy to solve the\nproximal mapping associated with the sparsity-inducing regularizer using\nnonlinear transforms. All the parameters in ISTA-Net (\\eg nonlinear transforms,\nshrinkage thresholds, step sizes, etc.) are learned end-to-end, rather than\nbeing hand-crafted. Moreover, considering that the residuals of natural images\nare more compressible, an enhanced version of ISTA-Net in the residual domain,\ndubbed {ISTA-Net}$^+$, is derived to further improve CS reconstruction.\nExtensive CS experiments demonstrate that the proposed ISTA-Nets outperform\nexisting state-of-the-art optimization-based and network-based CS methods by\nlarge margins, while maintaining fast computational speed. Our source codes are\navailable: \\textsl{http://jianzhang.tech/projects/ISTA-Net}.\ndetails: "}, {"id": 53, "contents": "title: State Gradients for RNN Memory Analysis\nauthors: Lyan Verwimp,Hugo Van hamme,Vincent Renkens,Patrick Wambacq\nabstract: We present a framework for analyzing what the state in RNNs remembers from\nits input embeddings. Our approach is inspired by backpropagation, in the sense\nthat we compute the gradients of the states with respect to the input\nembeddings. The gradient matrix is decomposed with Singular Value Decomposition\nto analyze which directions in the embedding space are best transferred to the\nhidden state space, characterized by the largest singular values. We apply our\napproach to LSTM language models and investigate to what extent and for how\nlong certain classes of words are remembered on average for a certain corpus.\nAdditionally, the extent to which a specific property or relationship is\nremembered by the RNN can be tracked by comparing a vector characterizing that\nproperty with the direction(s) in embedding space that are best preserved in\nhidden state space.\ndetails: "}, {"id": 54, "contents": "title: Convex Optimization with Unbounded Nonconvex Oracles using Simulated Annealing\nauthors: Oren Mangoubi,Nisheeth K. Vishnoi\nabstract: We consider the problem of minimizing a convex objective function $F$ when\none can only evaluate its noisy approximation $\\hat{F}$. Unless one assumes\nsome structure on the noise, $\\hat{F}$ may be an arbitrary nonconvex function,\nmaking the task of minimizing $F$ intractable. To overcome this, prior work has\noften focused on the case when $F(x)-\\hat{F}(x)$ is uniformly-bounded. In this\npaper we study the more general case when the noise has magnitude $\\alpha F(x)\n+ \\beta$ for some $\\alpha, \\beta > 0$, and present a polynomial time algorithm\nthat finds an approximate minimizer of $F$ for this noise model. Previously,\nMarkov chains, such as the stochastic gradient Langevin dynamics, have been\nused to arrive at approximate solutions to these optimization problems.\nHowever, for the noise model considered in this paper, no single temperature\nallows such a Markov chain to both mix quickly and concentrate near the global\nminimizer. We bypass this by combining \"simulated annealing\" with the\nstochastic gradient Langevin dynamics, and gradually decreasing the temperature\nof the chain in order to approach the global minimizer. As a corollary one can\napproximately minimize a nonconvex function that is close to a convex function;\nhowever, the closeness can deteriorate as one moves away from the optimum.\ndetails: "}, {"id": 55, "contents": "title: Incremental Sparse Bayesian Ordinal Regression\nauthors: Chang Li,Maarten de Rijke\nabstract: Ordinal Regression (OR) aims to model the ordering information between\ndifferent data categories, which is a crucial topic in multi-label learning. An\nimportant class of approaches to OR models the problem as a linear combination\nof basis functions that map features to a high dimensional non-linear space.\nHowever, most of the basis function-based algorithms are time consuming. We\npropose an incremental sparse Bayesian approach to OR tasks and introduce an\nalgorithm to sequentially learn the relevant basis functions in the ordinal\nscenario. Our method, called Incremental Sparse Bayesian Ordinal Regression\n(ISBOR), automatically optimizes the hyper-parameters via the type-II maximum\nlikelihood method. By exploiting fast marginal likelihood optimization, ISBOR\ncan avoid big matrix inverses, which is the main bottleneck in applying basis\nfunction-based algorithms to OR tasks on large-scale datasets. We show that\nISBOR can make accurate predictions with parsimonious basis functions while\noffering automatic estimates of the prediction uncertainty. Extensive\nexperiments on synthetic and real word datasets demonstrate the efficiency and\neffectiveness of ISBOR compared to other basis function-based OR approaches.\ndetails: "}, {"id": 56, "contents": "title: SNIPER: Efficient Multi-Scale Training\nauthors: Bharat Singh,Mahyar Najibi,Larry S. Davis\nabstract: We present SNIPER, an algorithm for performing efficient multi-scale training\nin instance level visual recognition tasks. Instead of processing every pixel\nin an image pyramid, SNIPER processes context regions around ground-truth\ninstances (referred to as chips) at the appropriate scale. For background\nsampling, these context-regions are generated using proposals extracted from a\nregion proposal network trained with a short learning schedule. Hence, the\nnumber of chips generated per image during training adaptively changes based on\nthe scene complexity. SNIPER only processes 30% more pixels compared to the\ncommonly used single scale training at 800x1333 pixels on the COCO dataset.\nBut, it also observes samples from extreme resolutions of the image pyramid,\nlike 1400x2000 pixels. As SNIPER operates on resampled low resolution chips\n(512x512 pixels), it can have a batch size as large as 20 on a single GPU even\nwith a ResNet-101 backbone. Therefore it can benefit from batch-normalization\nduring training without the need for synchronizing batch-normalization\nstatistics across GPUs. SNIPER brings training of instance level recognition\ntasks like object detection closer to the protocol for image classification and\nsuggests that the commonly accepted guideline that it is important to train on\nhigh resolution images for instance level visual recognition tasks might not be\ncorrect. Our implementation based on Faster-RCNN with a ResNet-101 backbone\nobtains an mAP of 47.6% on the COCO dataset for bounding box detection and can\nprocess 5 images per second during inference with a single GPU. Code is\navailable at https://github.com/MahyarNajibi/SNIPER/.\ndetails: "}, {"id": 57, "contents": "title: Constraining the Dynamics of Deep Probabilistic Models\nauthors: Marco Lorenzi,Maurizio Filippone\nabstract: We introduce a novel generative formulation of deep probabilistic models\nimplementing \"soft\" constraints on their function dynamics. In particular, we\ndevelop a flexible methodological framework where the modeled functions and\nderivatives of a given order are subject to inequality or equality constraints.\nWe then characterize the posterior distribution over model and constraint\nparameters through stochastic variational inference. As a result, the proposed\napproach allows for accurate and scalable uncertainty quantification on the\npredictions and on all parameters. We demonstrate the application of equality\nconstraints in the challenging problem of parameter inference in ordinary\ndifferential equation models, while we showcase the application of inequality\nconstraints on the problem of monotonic regression of count data. The proposed\napproach is extensively tested in several experimental settings, leading to\nhighly competitive results in challenging modeling applications, while offering\nhigh expressiveness, flexibility and scalability.\ndetails: "}, {"id": 58, "contents": "title: A Simple Reservoir Model of Working Memory with Real Values\nauthors: Anthony Strock,Nicolas Rougier,Xavier Hinaut\nabstract: The prefrontal cortex is known to be involved in many high-level cognitive\nfunctions, in particular, working memory. Here, we study to what extent a group\nof randomly connected units (namely an Echo State Network, ESN) can store and\nmaintain (as output) an arbitrary real value from a streamed input, i.e. can\nact as a sustained working memory unit. Furthermore, we explore to what extent\nsuch an architecture can take advantage of the stored value in order to produce\nnon-linear computations. Comparison between different architectures (with and\nwithout feedback, with and without a working memory unit) shows that an\nexplicit memory improves the performances.\ndetails: "}, {"id": 59, "contents": "title: Segmentation of Photovoltaic Module Cells in Uncalibrated Electroluminescence Images\nauthors: Sergiu Deitsch,Claudia Buerhop-Lutz,Evgenii Sovetkin,Ansgar Steland,Andreas Maier,Florian Gallwitz,Christian Riess\nabstract: High resolution electroluminescence (EL) images captured in the infrared spectrum allow to visually and non-destructively inspect the quality of photovoltaic (PV) modules. Currently, however, such a visual inspection requires trained experts to discern different kinds of defects, which is time-consuming and expensive. Automated segmentation of cells is therefore a key step in automating the visual inspection workflow. In this work, we propose a robust automated segmentation method for extraction of individual solar cells from EL images of PV modules. This enables controlled studies on large amounts of data to understanding the effects of module degradation over time-a process not yet fully understood. The proposed method infers in several steps a high-level solar module representation from low-level edge features. An important step in the algorithm is to formulate the segmentation problem in terms of lens calibration by exploiting the plumbline constraint. We evaluate our method on a dataset of various solar modules types containing a total of 408 solar cells with various defects. Our method robustly solves this task with a median weighted Jaccard index of 94.47% and an $F_1$ score of 97.62%, both indicating a very high similarity between automatically segmented and ground truth solar cell masks.\ndetails: "}, {"id": 60, "contents": "title: Dual Recovery Network with Online Compensation for Image Super-Resolution\nauthors: Sifeng Xia,Wenhan Yang,Jiaying Liu,Zongming Guo\nabstract: Image super-resolution (SR) methods essentially lead to a loss of some\nhigh-frequency (HF) information when predicting high-resolution (HR) images\nfrom low-resolution (LR) images without using external references. To address\nthis issue, we additionally utilize online retrieved data to facilitate image\nSR in a unified deep framework. A novel dual high-frequency recovery network\n(DHN) is proposed to predict an HR image with three parts: an LR image, an\ninternal inferred HF (IHF) map (HF missing part inferred solely from the LR\nimage) and an external extracted HF (EHF) map. In particular, we infer the HF\ninformation based on both the LR image and similar HR references which are\nretrieved online. For the EHF map, we align the references with affine\ntransformation and then in the aligned references, part of HF signals are\nextracted by the proposed DHN to compensate for the HF loss. Extensive\nexperimental results demonstrate that our DHN achieves notably better\nperformance than state-of-the-art SR methods.\ndetails: "}, {"id": 61, "contents": "title: HitNet: a neural network with capsules embedded in a Hit-or-Miss layer, extended with hybrid data augmentation and ghost capsules\nauthors: Adrien Deliège,Anthony Cioppa,Marc Van Droogenbroeck\nabstract: Neural networks designed for the task of classification have become a\ncommodity in recent years. Many works target the development of better\nnetworks, which results in a complexification of their architectures with more\nlayers, multiple sub-networks, or even the combination of multiple classifiers.\nIn this paper, we show how to redesign a simple network to reach excellent\nperformances, which are better than the results reproduced with CapsNet on\nseveral datasets, by replacing a layer with a Hit-or-Miss layer. This layer\ncontains activated vectors, called capsules, that we train to hit or miss a\ncentral capsule by tailoring a specific centripetal loss function. We also show\nhow our network, named HitNet, is capable of synthesizing a representative\nsample of the images of a given class by including a reconstruction network.\nThis possibility allows to develop a data augmentation step combining\ninformation from the data space and the feature space, resulting in a hybrid\ndata augmentation process. In addition, we introduce the possibility for\nHitNet, to adopt an alternative to the true target when needed by using the new\nconcept of ghost capsules, which is used here to detect potentially mislabeled\nimages in the training data.\ndetails: "}, {"id": 62, "contents": "title: The Information Autoencoding Family: A Lagrangian Perspective on Latent Variable Generative Models\nauthors: Shengjia Zhao,Jiaming Song,Stefano Ermon\nabstract: A large number of objectives have been proposed to train latent variable\ngenerative models. We show that many of them are Lagrangian dual functions of\nthe same primal optimization problem. The primal problem optimizes the mutual\ninformation between latent and visible variables, subject to the constraints of\naccurately modeling the data distribution and performing correct amortized\ninference. By choosing to maximize or minimize mutual information, and choosing\ndifferent Lagrange multipliers, we obtain different objectives including\nInfoGAN, ALI/BiGAN, ALICE, CycleGAN, beta-VAE, adversarial autoencoders, AVB,\nAS-VAE and InfoVAE. Based on this observation, we provide an exhaustive\ncharacterization of the statistical and computational trade-offs made by all\nthe training objectives in this class of Lagrangian duals. Next, we propose a\ndual optimization method where we optimize model parameters as well as the\nLagrange multipliers. This method achieves Pareto optimal solutions in terms of\noptimizing information and satisfying the constraints.\ndetails: "}, {"id": 63, "contents": "title: Semi-tied Units for Efficient Gating in LSTM and Highway Networks\nauthors: Chao Zhang,Philip Woodland\nabstract: Gating is a key technique used for integrating information from multiple\nsources by long short-term memory (LSTM) models and has recently also been\napplied to other models such as the highway network. Although gating is\npowerful, it is rather expensive in terms of both computation and storage as\neach gating unit uses a separate full weight matrix. This issue can be severe\nsince several gates can be used together in e.g. an LSTM cell. This paper\nproposes a semi-tied unit (STU) approach to solve this efficiency issue, which\nuses one shared weight matrix to replace those in all the units in the same\nlayer. The approach is termed \"semi-tied\" since extra parameters are used to\nseparately scale each of the shared output values. These extra scaling factors\nare associated with the network activation functions and result in the use of\nparameterised sigmoid, hyperbolic tangent, and rectified linear unit functions.\nSpeech recognition experiments using British English multi-genre broadcast data\nshowed that using STUs can reduce the calculation and storage cost by a factor\nof three for highway networks and four for LSTMs, while giving similar word\nerror rates to the original models.\ndetails: "}, {"id": 64, "contents": "title: Predicting Citation Counts with a Neural Network\nauthors: Tobias Mistele,Tom Price,Sabine Hossenfelder\nabstract: We here describe and present results of a simple neural network that predicts\nindividual researchers' future citation counts based on a variety of data from\nthe researchers' past. For publications available on the open access-server\narXiv.org we find a higher predictability than previous studies.\ndetails: "}, {"id": 65, "contents": "title: An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification\nauthors: Ahmed Imtiaz Humayun,Md. Tauhiduzzaman Khan,Shabnam Ghaffarzadegan,Zhe Feng,Taufiq Hasan\nabstract: In this work, we propose an ensemble of classifiers to distinguish between\nvarious degrees of abnormalities of the heart using Phonocardiogram (PCG)\nsignals acquired using digital stethoscopes in a clinical setting, for the\nINTERSPEECH 2018 Computational Paralinguistics (ComParE) Heart Beats\nSubChallenge. Our primary classification framework constitutes a convolutional\nneural network with 1D-CNN time-convolution (tConv) layers, which uses features\ntransferred from a model trained on the 2016 Physionet Heart Sound Database. We\nalso employ a Representation Learning (RL) approach to generate features in an\nunsupervised manner using Deep Recurrent Autoencoders and use Support Vector\nMachine (SVM) and Linear Discriminant Analysis (LDA) classifiers. Finally, we\nutilize an SVM classifier on a high-dimensional segment-level feature extracted\nusing various functionals on short-term acoustic features, i.e., Low-Level\nDescriptors (LLD). An ensemble of the three different approaches provides a\nrelative improvement of 11.13% compared to our best single sub-system in terms\nof the Unweighted Average Recall (UAR) performance metric on the evaluation\ndataset.\ndetails: "}, {"id": 66, "contents": "title: A unified strategy for implementing curiosity and empowerment driven reinforcement learning\nauthors: Ildefons Magrans de Abril,Ryota Kanai\nabstract: Although there are many approaches to implement intrinsically motivated\nartificial agents, the combined usage of multiple intrinsic drives remains\nstill a relatively unexplored research area. Specifically, we hypothesize that\na mechanism capable of quantifying and controlling the evolution of the\ninformation flow between the agent and the environment could be the fundamental\ncomponent for implementing a higher degree of autonomy into artificial\nintelligent agents. This paper propose a unified strategy for implementing two\nsemantically orthogonal intrinsic motivations: curiosity and empowerment.\nCuriosity reward informs the agent about the relevance of a recent agent\naction, whereas empowerment is implemented as the opposite information flow\nfrom the agent to the environment that quantifies the agent's potential of\ncontrolling its own future. We show that an additional homeostatic drive is\nderived from the curiosity reward, which generalizes and enhances the\ninformation gain of a classical curious/heterostatic reinforcement learning\nagent. We show how a shared internal model by curiosity and empowerment\nfacilitates a more efficient training of the empowerment function. Finally, we\ndiscuss future directions for further leveraging the interplay between these\ntwo intrinsic rewards.\ndetails: "}, {"id": 67, "contents": "title: Multi-Modal Data Augmentation for End-to-End ASR\nauthors: Adithya Renduchintala,Shuoyang Ding,Matthew Wiesner,Shinji Watanabe\nabstract: We present a new end-to-end architecture for automatic speech recognition\n(ASR) that can be trained using \\emph{symbolic} input in addition to the\ntraditional acoustic input. This architecture utilizes two separate encoders:\none for acoustic input and another for symbolic input, both sharing the\nattention and decoder parameters. We call this architecture a multi-modal data\naugmentation network (MMDA), as it can support multi-modal (acoustic and\nsymbolic) input and enables seamless mixing of large text datasets with\nsignificantly smaller transcribed speech corpora during training. We study\ndifferent ways of transforming large text corpora into a symbolic form suitable\nfor training our MMDA network. Our best MMDA setup obtains small improvements\non character error rate (CER), and as much as 7-10\\% relative word error rate\n(WER) improvement over a baseline both with and without an external language\nmodel.\ndetails: "}, {"id": 68, "contents": "title: Deforming Autoencoders: Unsupervised Disentangling of Shape and Appearance\nauthors: Zhixin Shu,Mihir Sahasrabudhe,Alp Guler,Dimitris Samaras,Nikos Paragios,Iasonas Kokkinos\nabstract: In this work we introduce Deforming Autoencoders, a generative model for\nimages that disentangles shape from appearance in an unsupervised manner. As in\nthe deformable template paradigm, shape is represented as a deformation between\na canonical coordinate system (`template') and an observed image, while\nappearance is modeled in `canonical', template, coordinates, thus discarding\nvariability due to deformations. We introduce novel techniques that allow this\napproach to be deployed in the setting of autoencoders and show that this\nmethod can be used for unsupervised group-wise image alignment. We show\nexperiments with expression morphing in humans, hands, and digits, face\nmanipulation, such as shape and appearance interpolation, as well as\nunsupervised landmark localization. A more powerful form of unsupervised\ndisentangling becomes possible in template coordinates, allowing us to\nsuccessfully decompose face images into shading and albedo, and further\nmanipulate face images.\ndetails: "}, {"id": 69, "contents": "title: Conditional Affordance Learning for Driving in Urban Environments\nauthors: Axel Sauer,Nikolay Savinov,Andreas Geiger\nabstract: Most existing approaches to autonomous driving fall into one of two\ncategories: modular pipelines, that build an extensive model of the\nenvironment, and imitation learning approaches, that map images directly to\ncontrol outputs. A recently proposed third paradigm, direct perception, aims to\ncombine the advantages of both by using a neural network to learn appropriate\nlow-dimensional intermediate representations. However, existing direct\nperception approaches are restricted to simple highway situations, lacking the\nability to navigate intersections, stop at traffic lights or respect speed\nlimits. In this work, we propose a direct perception approach which maps video\ninput to intermediate representations suitable for autonomous navigation in\ncomplex urban environments given high-level directional inputs. Compared to\nstate-of-the-art reinforcement and conditional imitation learning approaches,\nwe achieve an improvement of up to 68 % in goal-directed navigation on the\nchallenging CARLA simulation benchmark. In addition, our approach is the first\nto handle traffic lights and speed signs by using image-level labels only, as\nwell as smooth car-following, resulting in a significant reduction of traffic\naccidents in simulation.\ndetails: "}, {"id": 70, "contents": "title: Power-Grid Controller Anomaly Detection with Enhanced Temporal Deep Learning\nauthors: Zecheng He,Aswin Raghavan,Guangyuan Hu,Sek Chai,Ruby Lee\nabstract: Controllers of security-critical cyber-physical systems, like the power grid, are a very important class of computer systems. Attacks against the control code of a power-grid system, especially zero-day attacks, can be catastrophic. Earlier detection of the anomalies can prevent further damage. However, detecting zero-day attacks is extremely challenging because they have no known code and have unknown behavior. Furthermore, if data collected from the controller is transferred to a server through networks for analysis and detection of anomalous behavior, this creates a very large attack surface and also delays detection. In order to address this problem, we propose Reconstruction Error Distribution (RED) of Hardware Performance Counters (HPCs), and a data-driven defense system based on it. Specifically, we first train a temporal deep learning model, using only normal HPC readings from legitimate processes that run daily in these power-grid systems, to model the normal behavior of the power-grid controller. Then, we run this model using real-time data from commonly available HPCs. We use the proposed RED to enhance the temporal deep learning detection of anomalous behavior, by estimating distribution deviations from the normal behavior with an effective statistical test. Experimental results on a real power-grid controller show that we can detect anomalous behavior with high accuracy (>99.9%), nearly zero false positives and short (<360ms) latency.\ndetails: "}, {"id": 71, "contents": "title: Women also Snowboard: Overcoming Bias in Captioning Models\nauthors: Kaylee Burns,Lisa Anne Hendricks,Kate Saenko,Trevor Darrell,Anna Rohrbach\nabstract: Most machine learning methods are known to capture and exploit biases of the\ntraining data. While some biases are beneficial for learning, others are\nharmful. Specifically, image captioning models tend to exaggerate biases\npresent in training data (e.g., if a word is present in 60% of training\nsentences, it might be predicted in 70% of sentences at test time). This can\nlead to incorrect captions in domains where unbiased captions are desired, or\nrequired, due to over-reliance on the learned prior and image context. In this\nwork we investigate generation of gender-specific caption words (e.g. man,\nwoman) based on the person's appearance or the image context. We introduce a\nnew Equalizer model that ensures equal gender probability when gender evidence\nis occluded in a scene and confident predictions when gender evidence is\npresent. The resulting model is forced to look at a person rather than use\ncontextual cues to make a gender-specific predictions. The losses that comprise\nour model, the Appearance Confusion Loss and the Confident Loss, are general,\nand can be added to any description model in order to mitigate impacts of\nunwanted bias in a description dataset. Our proposed model has lower error than\nprior work when describing images with people and mentioning their gender and\nmore closely matches the ground truth ratio of sentences including women to\nsentences including men. We also show that unlike other approaches, our model\nis indeed more often looking at people when predicting their gender.\ndetails: "}, {"id": 72, "contents": "title: Boosted Density Estimation Remastered\nauthors: Zac Cranko,Richard Nock\nabstract: There has recently been a steady increase in the number iterative approaches\nto density estimation. However, an accompanying burst of formal convergence\nguarantees has not followed; all results pay the price of heavy assumptions\nwhich are often unrealistic or hard to check. The Generative Adversarial\nNetwork (GAN) literature --- seemingly orthogonal to the aforementioned pursuit\n--- has had the side effect of a renewed interest in variational divergence\nminimisation (notably $f$-GAN). We show that by introducing a weak learning\nassumption (in the sense of the classical boosting framework) we are able to\nimport some recent results from the GAN literature to develop an iterative\nboosted density estimation algorithm, including formal convergence results with\nrates, that does not suffer the shortcomings other approaches. We show that the\ndensity fit is an exponential family, and as part of our analysis obtain an\nimproved variational characterisation of $f$-GAN.\ndetails: "}, {"id": 73, "contents": "title: Disturbance Grassmann Kernels for Subspace-Based Learning\nauthors: Junyuan Hong,Huanhuan Chen,Feng Lin\nabstract: In this paper, we focus on subspace-based learning problems, where data\nelements are linear subspaces instead of vectors. To handle this kind of data,\nGrassmann kernels were proposed to measure the space structure and used with\nclassifiers, e.g., Support Vector Machines (SVMs). However, the existing\ndiscriminative algorithms mostly ignore the instability of subspaces, which\nwould cause the classifiers misled by disturbed instances. Thus we propose\nconsidering all potential disturbance of subspaces in learning processes to\nobtain more robust classifiers. Firstly, we derive the dual optimization of\nlinear classifiers with disturbance subject to a known distribution, resulting\nin a new kernel, Disturbance Grassmann (DG) kernel. Secondly, we research into\ntwo kinds of disturbance, relevant to the subspace matrix and singular values\nof bases, with which we extend the Projection kernel on Grassmann manifolds to\ntwo new kernels. Experiments on action data indicate that the proposed kernels\nperform better compared to state-of-the-art subspace-based methods, even in a\nworse environment.\ndetails: "}, {"id": 74, "contents": "title: Entity-Aware Language Model as an Unsupervised Reranker\nauthors: Mohammad Sadegh Rasooli,Sarangarajan Parthasarathy\nabstract: In language modeling, it is difficult to incorporate entity relationships\nfrom a knowledge-base. One solution is to use a reranker trained with global\nfeatures, in which global features are derived from n-best lists. However,\ntraining such a reranker requires manually annotated n-best lists, which is\nexpensive to obtain. We propose a method based on the contrastive estimation\nmethod that alleviates the need for such data. Experiments in the music domain\ndemonstrate that global features, as well as features extracted from an\nexternal knowledge-base, can be incorporated into our reranker. Our final\nmodel, a simple ensemble of a language model and reranker, achieves a 0.44\\%\nabsolute word error rate improvement over an LSTM language model on the blind\ntest data.\ndetails: "}, {"id": 75, "contents": "title: Co-training Embeddings of Knowledge Graphs and Entity Descriptions for Cross-lingual Entity Alignment\nauthors: Muhao Chen,Yingtao Tian,Kai-Wei Chang,Steven Skiena,Carlo Zaniolo\nabstract: Multilingual knowledge graph (KG) embeddings provide latent semantic\nrepresentations of entities and structured knowledge with cross-lingual\ninferences, which benefit various knowledge-driven cross-lingual NLP tasks.\nHowever, precisely learning such cross-lingual inferences is usually hindered\nby the low coverage of entity alignment in many KGs. Since many multilingual\nKGs also provide literal descriptions of entities, in this paper, we introduce\nan embedding-based approach which leverages a weakly aligned multilingual KG\nfor semi-supervised cross-lingual learning using entity descriptions. Our\napproach performs co-training of two embedding models, i.e. a multilingual KG\nembedding model and a multilingual literal description embedding model. The\nmodels are trained on a large Wikipedia-based trilingual dataset where most\nentity alignment is unknown to training. Experimental results show that the\nperformance of the proposed approach on the entity alignment task improves at\neach iteration of co-training, and eventually reaches a stage at which it\nsignificantly surpasses previous approaches. We also show that our approach has\npromising abilities for zero-shot entity alignment, and cross-lingual KG\ncompletion.\ndetails: "}, {"id": 76, "contents": "title: Video Salient Object Detection Using Spatiotemporal Deep Features\nauthors: Trung-Nghia Le,Akihiro Sugimoto\nabstract: This paper presents a method for detecting salient objects in videos where\ntemporal information in addition to spatial information is fully taken into\naccount. Following recent reports on the advantage of deep features over\nconventional hand-crafted features, we propose a new set of SpatioTemporal Deep\n(STD) features that utilize local and global contexts over frames. We also\npropose new SpatioTemporal Conditional Random Field (STCRF) to compute saliency\nfrom STD features. STCRF is our extension of CRF to the temporal domain and\ndescribes the relationships among neighboring regions both in a frame and over\nframes. STCRF leads to temporally consistent saliency maps over frames,\ncontributing to the accurate detection of salient objects' boundaries and noise\nreduction during detection. Our proposed method first segments an input video\ninto multiple scales and then computes a saliency map at each scale level using\nSTD features with STCRF. The final saliency map is computed by fusing saliency\nmaps at different scale levels. Our experiments, using publicly available\nbenchmark datasets, confirm that the proposed method significantly outperforms\nstate-of-the-art methods. We also applied our saliency computation to the video\nobject segmentation task, showing that our method outperforms existing video\nobject segmentation methods.\ndetails: "}, {"id": 77, "contents": "title: Reinforcement Learning in Rich-Observation MDPs using Spectral Methods\nauthors: Kamyar Azizzadenesheli,Alessandro Lazaric,Animashree Anandkumar\nabstract: Reinforcement learning (RL) in Markov decision processes (MDPs) with large\nstate spaces is a challenging problem. The performance of standard RL\nalgorithms degrades drastically with the dimensionality of state space.\nHowever, in practice, these large MDPs typically incorporate a latent or hidden\nlow-dimensional structure. In this paper, we study the setting of\nrich-observation Markov decision processes (ROMDP), where there are a small\nnumber of hidden states which possess an injective mapping to the observation\nstates. In other words, every observation state is generated through a single\nhidden state, and this mapping is unknown a priori. We introduce a spectral\ndecomposition method that consistently learns this mapping, and more\nimportantly, achieves it with low regret. The estimated mapping is integrated\ninto an optimistic RL algorithm (UCRL), which operates on the estimated hidden\nspace. We derive finite-time regret bounds for our algorithm with a weak\ndependence on the dimensionality of the observed space. In fact, our algorithm\nasymptotically achieves the same average regret as the oracle UCRL algorithm,\nwhich has the knowledge of the mapping from hidden to observed spaces. Thus, we\nderive an efficient spectral RL algorithm for ROMDPs.\ndetails: "}, {"id": 78, "contents": "title: Breaking Transferability of Adversarial Samples with Randomness\nauthors: Yan Zhou,Murat Kantarcioglu,Bowei Xi\nabstract: We investigate the role of transferability of adversarial attacks in the\nobserved vulnerabilities of Deep Neural Networks (DNNs). We demonstrate that\nintroducing randomness to the DNN models is sufficient to defeat adversarial\nattacks, given that the adversary does not have an unlimited attack budget.\nInstead of making one specific DNN model robust to perfect knowledge attacks\n(a.k.a, white box attacks), creating randomness within an army of DNNs\ncompletely eliminates the possibility of perfect knowledge acquisition,\nresulting in a significantly more robust DNN ensemble against the strongest\nform of attacks. We also show that when the adversary has an unlimited budget\nof data perturbation, all defensive techniques would eventually break down as\nthe budget increases. Therefore, it is important to understand the game saddle\npoint where the adversary would not further pursue this endeavor.\n  Furthermore, we explore the relationship between attack severity and decision\nboundary robustness in the version space. We empirically demonstrate that by\nsimply adding a small Gaussian random noise to the learned weights, a DNN model\ncan increase its resilience to adversarial attacks by as much as 74.2%. More\nimportantly, we show that by randomly activating/revealing a model from a pool\nof pre-trained DNNs at each query request, we can put a tremendous strain on\nthe adversary's attack strategies. We compare our randomization techniques to\nthe Ensemble Adversarial Training technique and show that our randomization\ntechniques are superior under different attack budget constraints.\ndetails: "}, {"id": 79, "contents": "title: The RBO Dataset of Articulated Objects and Interactions\nauthors: Roberto Martín-Martín,Clemens Eppner,Oliver Brock\nabstract: We present a dataset with models of 14 articulated objects commonly found in\nhuman environments and with RGB-D video sequences and wrenches recorded of\nhuman interactions with them. The 358 interaction sequences total 67 minutes of\nhuman manipulation under varying experimental conditions (type of interaction,\nlighting, perspective, and background). Each interaction with an object is\nannotated with the ground truth poses of its rigid parts and the kinematic\nstate obtained by a motion capture system. For a subset of 78 sequences (25\nminutes), we also measured the interaction wrenches. The object models contain\ntextured three-dimensional triangle meshes of each link and their motion\nconstraints. We provide Python scripts to download and visualize the data. The\ndata is available at https://tu-rbo.github.io/articulated-objects/ and hosted\nat https://zenodo.org/record/1036660/.\ndetails: "}, {"id": 80, "contents": "title: Learning Policy Representations in Multiagent Systems\nauthors: Aditya Grover,Maruan Al-Shedivat,Jayesh K. Gupta,Yura Burda,Harrison Edwards\nabstract: Modeling agent behavior is central to understanding the emergence of complex\nphenomena in multiagent systems. Prior work in agent modeling has largely been\ntask-specific and driven by hand-engineering domain-specific prior knowledge.\nWe propose a general learning framework for modeling agent behavior in any\nmultiagent system using only a handful of interaction data. Our framework casts\nagent modeling as a representation learning problem. Consequently, we construct\na novel objective inspired by imitation learning and agent identification and\ndesign an algorithm for unsupervised learning of representations of agent\npolicies. We demonstrate empirically the utility of the proposed framework in\n(i) a challenging high-dimensional competitive environment for continuous\ncontrol and (ii) a cooperative environment for communication, on supervised\npredictive tasks, unsupervised clustering, and policy optimization using deep\nreinforcement learning.\ndetails: "}, {"id": 81, "contents": "title: Sub-Gaussian estimators of the mean of a random matrix with heavy-tailed entries\nauthors: Stanislav Minsker\nabstract: Estimation of the covariance matrix has attracted a lot of attention of the\nstatistical research community over the years, partially due to important\napplications such as Principal Component Analysis. However, frequently used\nempirical covariance estimator (and its modifications) is very sensitive to\noutliers in the data. As P. J. Huber wrote in 1964, \"...This raises a question\nwhich could have been asked already by Gauss, but which was, as far as I know,\nonly raised a few years ago (notably by Tukey): what happens if the true\ndistribution deviates slightly from the assumed normal one? As is now well\nknown, the sample mean then may have a catastrophically bad performance...\"\nMotivated by this question, we develop a new estimator of the (element-wise)\nmean of a random matrix, which includes covariance estimation problem as a\nspecial case. Assuming that the entries of a matrix possess only finite second\nmoment, this new estimator admits sub-Gaussian or sub-exponential concentration\naround the unknown mean in the operator norm. We will explain the key ideas\nbehind our construction, as well as applications to covariance estimation and\nmatrix completion problems.\ndetails: "}, {"id": 82, "contents": "title: Fast Convex Pruning of Deep Neural Networks\nauthors: Alireza Aghasi,Afshin Abdi,Justin Romberg\nabstract: We develop a fast, tractable technique called Net-Trim for simplifying a\ntrained neural network. The method is a convex post-processing module, which\nprunes (sparsifies) a trained network layer by layer, while preserving the\ninternal responses. We present a comprehensive analysis of Net-Trim from both\nthe algorithmic and sample complexity standpoints, centered on a fast, scalable\nconvex optimization program. Our analysis includes consistency results between\nthe initial and retrained models before and after Net-Trim application and\nguarantees on the number of training samples needed to discover a network that\ncan be expressed using a certain number of nonzero terms. Specifically, if\nthere is a set of weights that uses at most $s$ terms that can re-create the\nlayer outputs from the layer inputs, we can find these weights from\n$\\mathcal{O}(s\\log N/s)$ samples, where $N$ is the input size. These\ntheoretical results are similar to those for sparse regression using the Lasso,\nand our analysis uses some of the same recently-developed tools (namely recent\nresults on the concentration of measure and convex analysis). Finally, we\npropose an algorithmic framework based on the alternating direction method of\nmultipliers (ADMM), which allows a fast and simple implementation of Net-Trim\nfor network pruning and compression.\ndetails: "}, {"id": 83, "contents": "title: Cross-modality image synthesis from unpaired data using CycleGAN: Effects of gradient consistency loss and training data size\nauthors: Yuta Hiasa,Yoshito Otake,Masaki Takao,Takumi Matsuoka,Kazuma Takashima,Jerry L. Prince,Nobuhiko Sugano,Yoshinobu Sato\nabstract: CT is commonly used in orthopedic procedures. MRI is used along with CT to\nidentify muscle structures and diagnose osteonecrosis due to its superior soft\ntissue contrast. However, MRI has poor contrast for bone structures. Clearly,\nit would be helpful if a corresponding CT were available, as bone boundaries\nare more clearly seen and CT has standardized (i.e., Hounsfield) units.\nTherefore, we aim at MR-to-CT synthesis. The CycleGAN was successfully applied\nto unpaired CT and MR images of the head, these images do not have as much\nvariation of intensity pairs as do images in the pelvic region due to the\npresence of joints and muscles. In this paper, we extended the CycleGAN\napproach by adding the gradient consistency loss to improve the accuracy at the\nboundaries. We conducted two experiments. To evaluate image synthesis, we\ninvestigated dependency of image synthesis accuracy on 1) the number of\ntraining data and 2) the gradient consistency loss. To demonstrate the\napplicability of our method, we also investigated a segmentation accuracy on\nsynthesized images.\ndetails: "}, {"id": 84, "contents": "title: Self-Attentive Neural Collaborative Filtering\nauthors: Yi Tay,Shuai Zhang,Luu Anh Tuan,Siu Cheung Hui\nabstract: This paper has been withdrawn as we discovered a bug in our tensorflow\nimplementation that involved accidental mixing of vectors across batches. This\nlead to different inference results given different batch sizes which is\ncompletely strange. The performance scores still remain the same but we\nconcluded that it was not the self-attention that contributed to the\nperformance. We are withdrawing the paper because this renders the main claim\nof the paper false. Thanks to Guan Xinyu from NUS for discovering this issue in\nour previously open source code.\ndetails: "}, {"id": 85, "contents": "title: NCRF++: An Open-source Neural Sequence Labeling Toolkit\nauthors: Jie Yang,Yue Zhang\nabstract: This paper describes NCRF++, a toolkit for neural sequence labeling. NCRF++\nis designed for quick implementation of different neural sequence labeling\nmodels with a CRF inference layer. It provides users with an inference for\nbuilding the custom model structure through configuration file with flexible\nneural feature design and utilization. Built on PyTorch, the core operations\nare calculated in batch, making the toolkit efficient with the acceleration of\nGPU. It also includes the implementations of most state-of-the-art neural\nsequence labeling models such as LSTM-CRF, facilitating reproducing and\nrefinement on those methods.\ndetails: "}, {"id": 86, "contents": "title: Online Prediction of Switching Graph Labelings with Cluster Specialists\nauthors: Mark Herbster,James Robinson\nabstract: We address the problem of predicting the labeling of a graph in an online setting when the labeling is changing over time. We present an algorithm based on a specialist approach; we develop the machinery of cluster specialists which probabilistically exploits the cluster structure in the graph. Our algorithm has two variants, one of which surprisingly only requires $\\mathcal{O}(\\log n)$ time on any trial $t$ on an $n$-vertex graph, an exponential speed up over existing methods. We prove switching mistake-bound guarantees for both variants of our algorithm. Furthermore these mistake bounds smoothly vary with the magnitude of the change between successive labelings. We perform experiments on Chicago Divvy Bicycle Sharing data and show that our algorithms significantly outperform an existing algorithm (a kernelized Perceptron) as well as several natural benchmarks.\ndetails: "}, {"id": 87, "contents": "title: Compressed Sensing with Deep Image Prior and Learned Regularization\nauthors: Dave Van Veen,Ajil Jalal,Mahdi Soltanolkotabi,Eric Price,Sriram Vishwanath,Alexandros G. Dimakis\nabstract: We propose a novel method for compressed sensing recovery using untrained deep generative models. Our method is based on the recently proposed Deep Image Prior (DIP), wherein the convolutional weights of the network are optimized to match the observed measurements. We show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods. Unlike various learned approaches based on generative models, our method does not require pre-training over large datasets. We further introduce a novel learned regularization technique, which incorporates prior information on the network weights. This reduces reconstruction error, especially for noisy measurements. Finally, we prove that, using the DIP optimization approach, moderately overparameterized single-layer networks can perfectly fit any signal despite the non-convex nature of the fitting problem. This theoretical result provides justification for early stopping.\ndetails: "}, {"id": 88, "contents": "title: Subspace Embedding and Linear Regression with Orlicz Norm\nauthors: Alexandr Andoni,Chengyu Lin,Ying Sheng,Peilin Zhong,Ruiqi Zhong\nabstract: We consider a generalization of the classic linear regression problem to the\ncase when the loss is an Orlicz norm. An Orlicz norm is parameterized by a\nnon-negative convex function $G:\\mathbb{R}_+\\rightarrow\\mathbb{R}_+$ with\n$G(0)=0$: the Orlicz norm of a vector $x\\in\\mathbb{R}^n$ is defined as $\n\\|x\\|_G=\\inf\\left\\{\\alpha>0\\large\\mid\\sum_{i=1}^n G(|x_i|/\\alpha)\\leq\n1\\right\\}. $ We consider the cases where the function $G(\\cdot)$ grows\nsubquadratically. Our main result is based on a new oblivious embedding which\nembeds the column space of a given matrix $A\\in\\mathbb{R}^{n\\times d}$ with\nOrlicz norm into a lower dimensional space with $\\ell_2$ norm. Specifically, we\nshow how to efficiently find an embedding matrix $S\\in\\mathbb{R}^{m\\times\nn},m<n$ such that $\\forall x\\in\\mathbb{R}^{d},\\Omega(1/(d\\log n)) \\cdot\n\\|Ax\\|_G\\leq \\|SAx\\|_2\\leq O(d^2\\log n) \\cdot \\|Ax\\|_G.$ By applying this\nsubspace embedding technique, we show an approximation algorithm for the\nregression problem $\\min_{x\\in\\mathbb{R}^d} \\|Ax-b\\|_G$, up to a $O(d\\log^2 n)$\nfactor. As a further application of our techniques, we show how to also use\nthem to improve on the algorithm for the $\\ell_p$ low rank matrix approximation\nproblem for $1\\leq p<2$.\ndetails: "}, {"id": 89, "contents": "title: Scalable Methods for 8-bit Training of Neural Networks\nauthors: Ron Banner,Itay Hubara,Elad Hoffer,Daniel Soudry\nabstract: Quantized Neural Networks (QNNs) are often used to improve network efficiency\nduring the inference phase, i.e. after the network has been trained. Extensive\nresearch in the field suggests many different quantization schemes. Still, the\nnumber of bits required, as well as the best quantization scheme, are yet\nunknown. Our theoretical analysis suggests that most of the training process is\nrobust to substantial precision reduction, and points to only a few specific\noperations that require higher precision. Armed with this knowledge, we\nquantize the model parameters, activations and layer gradients to 8-bit,\nleaving at a higher precision only the final step in the computation of the\nweight gradients. Additionally, as QNNs require batch-normalization to be\ntrained at high precision, we introduce Range Batch-Normalization (BN) which\nhas significantly higher tolerance to quantization noise and improved\ncomputational complexity. Our simulations show that Range BN is equivalent to\nthe traditional batch norm if a precise scale adjustment, which can be\napproximated analytically, is applied. To the best of the authors' knowledge,\nthis work is the first to quantize the weights, activations, as well as a\nsubstantial volume of the gradients stream, in all layers (including batch\nnormalization) to 8-bit while showing state-of-the-art results over the\nImageNet-1K dataset.\ndetails: "}, {"id": 90, "contents": "title: A Novel Hybrid Machine Learning Model for Auto-Classification of Retinal Diseases\nauthors: C. -H. Huck Yang,Jia-Hong Huang,Fangyu Liu,Fang-Yi Chiu,Mengya Gao,Weifeng Lyu,I-Hung Lin M. D.,Jesper Tegner\nabstract: Automatic clinical diagnosis of retinal diseases has emerged as a promising\napproach to facilitate discovery in areas with limited access to specialists.\nWe propose a novel visual-assisted diagnosis hybrid model based on the support\nvector machine (SVM) and deep neural networks (DNNs). The model incorporates\ncomplementary strengths of DNNs and SVM. Furthermore, we present a new clinical\nretina label collection for ophthalmology incorporating 32 retina diseases\nclasses. Using EyeNet, our model achieves 89.73% diagnosis accuracy and the\nmodel performance is comparable to the professional ophthalmologists.\ndetails: "}, {"id": 91, "contents": "title: Learning to Evaluate Image Captioning\nauthors: Yin Cui,Guandao Yang,Andreas Veit,Xun Huang,Serge Belongie\nabstract: Evaluation metrics for image captioning face two challenges. Firstly,\ncommonly used metrics such as CIDEr, METEOR, ROUGE and BLEU often do not\ncorrelate well with human judgments. Secondly, each metric has well known blind\nspots to pathological caption constructions, and rule-based metrics lack\nprovisions to repair such blind spots once identified. For example, the newly\nproposed SPICE correlates well with human judgments, but fails to capture the\nsyntactic structure of a sentence. To address these two challenges, we propose\na novel learning based discriminative evaluation metric that is directly\ntrained to distinguish between human and machine-generated captions. In\naddition, we further propose a data augmentation scheme to explicitly\nincorporate pathological transformations as negative examples during training.\nThe proposed metric is evaluated with three kinds of robustness tests and its\ncorrelation with human judgments. Extensive experiments show that the proposed\ndata augmentation scheme not only makes our metric more robust toward several\npathological transformations, but also improves its correlation with human\njudgments. Our metric outperforms other metrics on both caption level human\ncorrelation in Flickr 8k and system level human correlation in COCO. The\nproposed approach could be served as a learning based evaluation metric that is\ncomplementary to existing rule-based metrics.\ndetails: "}, {"id": 92, "contents": "title: High-speed Tracking with Multi-kernel Correlation Filters\nauthors: Ming Tang,Bin Yu,Fan Zhang,Jinqiao Wang\nabstract: Correlation filter (CF) based trackers are currently ranked top in terms of\ntheir performances. Nevertheless, only some of them, such as\nKCF~\\cite{henriques15} and MKCF~\\cite{tangm15}, are able to exploit the\npowerful discriminability of non-linear kernels. Although MKCF achieves more\npowerful discriminability than KCF through introducing multi-kernel learning\n(MKL) into KCF, its improvement over KCF is quite limited and its computational\nburden increases significantly in comparison with KCF. In this paper, we will\nintroduce the MKL into KCF in a different way than MKCF. We reformulate the MKL\nversion of CF objective function with its upper bound, alleviating the negative\nmutual interference of different kernels significantly. Our novel MKCF tracker,\nMKCFup, outperforms KCF and MKCF with large margins and can still work at very\nhigh fps. Extensive experiments on public datasets show that our method is\nsuperior to state-of-the-art algorithms for target objects of small move at\nvery high speed.\ndetails: "}, {"id": 93, "contents": "title: Feature Learning and Classification in Neuroimaging: Predicting Cognitive Impairment from Magnetic Resonance Imaging\nauthors: Shan Shi,Farouk Nathoo\nabstract: Due to the rapid innovation of technology and the desire to find and employ\nbiomarkers for neurodegenerative disease, high-dimensional data classification\nproblems are routinely encountered in neuroimaging studies. To avoid\nover-fitting and to explore relationships between disease and potential\nbiomarkers, feature learning and selection plays an important role in\nclassifier construction and is an important area in machine learning. In this\narticle, we review several important feature learning and selection techniques\nincluding lasso-based methods, PCA, the two-sample t-test, and stacked\nauto-encoders. We compare these approaches using a numerical study involving\nthe prediction of Alzheimer's disease from Magnetic Resonance Imaging.\ndetails: "}, {"id": 94, "contents": "title: One-to-one Mapping between Stimulus and Neural State: Memory and Classification\nauthors: Sizhong Lan\nabstract: Synaptic strength can be seen as probability to propagate impulse, and\naccording to synaptic plasticity, function could exist from propagation\nactivity to synaptic strength. If the function satisfies constraints such as\ncontinuity and monotonicity, neural network under external stimulus will always\ngo to fixed point, and there could be one-to-one mapping between external\nstimulus and synaptic strength at fixed point. In other words, neural network\n\"memorizes\" external stimulus in its synapses. A biological classifier is\nproposed to utilize this mapping.\ndetails: "}, {"id": 95, "contents": "title: Negative Learning Rates and P-Learning\nauthors: Devon Merrill\nabstract: We present a method of training a differentiable function approximator for a\nregression task using negative examples. We effect this training using negative\nlearning rates. We also show how this method can be used to perform direct\npolicy learning in a reinforcement learning setting.\ndetails: "}, {"id": 96, "contents": "title: Measuring Semantic Coherence of a Conversation\nauthors: Svitlana Vakulenko,Maarten de Rijke,Michael Cochez,Vadim Savenkov,Axel Polleres\nabstract: Conversational systems have become increasingly popular as a way for humans\nto interact with computers. To be able to provide intelligent responses,\nconversational systems must correctly model the structure and semantics of a\nconversation. We introduce the task of measuring semantic (in)coherence in a\nconversation with respect to background knowledge, which relies on the\nidentification of semantic relations between concepts introduced during a\nconversation. We propose and evaluate graph-based and machine learning-based\napproaches for measuring semantic coherence using knowledge graphs, their\nvector space embeddings and word embedding models, as sources of background\nknowledge. We demonstrate how these approaches are able to uncover different\ncoherence patterns in conversations on the Ubuntu Dialogue Corpus.\ndetails: "}, {"id": 97, "contents": "title: Learning a Prior over Intent via Meta-Inverse Reinforcement Learning\nauthors: Kelvin Xu,Ellis Ratner,Anca Dragan,Sergey Levine,Chelsea Finn\nabstract: A significant challenge for the practical application of reinforcement learning in the real world is the need to specify an oracle reward function that correctly defines a task. Inverse reinforcement learning (IRL) seeks to avoid this challenge by instead inferring a reward function from expert behavior. While appealing, it can be impractically expensive to collect datasets of demonstrations that cover the variation common in the real world (e.g. opening any type of door). Thus in practice, IRL must commonly be performed with only a limited set of demonstrations where it can be exceedingly difficult to unambiguously recover a reward function. In this work, we exploit the insight that demonstrations from other tasks can be used to constrain the set of possible reward functions by learning a \"prior\" that is specifically optimized for the ability to infer expressive reward functions from limited numbers of demonstrations. We demonstrate that our method can efficiently recover rewards from images for novel tasks and provide intuition as to how our approach is analogous to learning a prior.\ndetails: "}, {"id": 98, "contents": "title: Gated Path Planning Networks\nauthors: Lisa Lee,Emilio Parisotto,Devendra Singh Chaplot,Eric Xing,Ruslan Salakhutdinov\nabstract: Value Iteration Networks (VINs) are effective differentiable path planning\nmodules that can be used by agents to perform navigation while still\nmaintaining end-to-end differentiability of the entire architecture. Despite\ntheir effectiveness, they suffer from several disadvantages including training\ninstability, random seed sensitivity, and other optimization problems. In this\nwork, we reframe VINs as recurrent-convolutional networks which demonstrates\nthat VINs couple recurrent convolutions with an unconventional max-pooling\nactivation. From this perspective, we argue that standard gated recurrent\nupdate equations could potentially alleviate the optimization issues plaguing\nVIN. The resulting architecture, which we call the Gated Path Planning Network,\nis shown to empirically outperform VIN on a variety of metrics such as learning\nspeed, hyperparameter sensitivity, iteration count, and even generalization.\nFurthermore, we show that this performance gap is consistent across different\nmaze transition types, maze sizes and even show success on a challenging 3D\nenvironment, where the planner is only provided with first-person RGB images.\ndetails: "}, {"id": 99, "contents": "title: An Improved Text Sentiment Classification Model Using TF-IDF and Next Word Negation\nauthors: Bijoyan Das,Sarit Chakraborty\nabstract: With the rapid growth of Text sentiment analysis, the demand for automatic\nclassification of electronic documents has increased by leaps and bound. The\nparadigm of text classification or text mining has been the subject of many\nresearch works in recent time. In this paper we propose a technique for text\nsentiment classification using term frequency- inverse document frequency\n(TF-IDF) along with Next Word Negation (NWN). We have also compared the\nperformances of binary bag of words model, TF-IDF model and TF-IDF with next\nword negation (TF-IDF-NWN) model for text classification. Our proposed model is\nthen applied on three different text mining algorithms and we found the Linear\nSupport vector machine (LSVM) is the most appropriate to work with our proposed\nmodel. The achieved results show significant increase in accuracy compared to\nearlier methods.\ndetails: "}]